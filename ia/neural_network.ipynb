{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.onnx \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and columns in one JSON file is (132, 6)\n"
     ]
    }
   ],
   "source": [
    "df_shape = df.shape\n",
    "print(f'Rows and columns in one JSON file is {df_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 columns in one JSON file is                    name artist  year gender   likes  bought\n",
      "0                 Queen  Queen  1973   Rock  3258.0    True\n",
      "1              Queen II  Queen  1974   Rock  4017.0    True\n",
      "2    Sheer Heart Attack  Queen  1974   Rock  2427.0   False\n",
      "3  A Night at the Opera  Queen  1975   Rock  2712.0   False\n",
      "4     News of the World  Queen  1977   Rock  3488.0    True\n",
      "5                  Jazz  Queen  1978   Rock  1377.0   False\n",
      "6              The Game  Queen  1980   Rock  6636.0    True\n",
      "7             Hot Space  Queen  1982   Rock  1762.0   False\n",
      "8             The Works  Queen  1984   Rock  5530.0   False\n",
      "9       A Kind of Magic  Queen  1986   Rock  3328.0    True\n"
     ]
    }
   ],
   "source": [
    "df_rows = df.head(10)\n",
    "print(f'First 10 columns in one JSON file is {df_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are :\n",
      "#########\n",
      "name\n",
      "artist\n",
      "year\n",
      "gender\n",
      "likes\n",
      "bought\n"
     ]
    }
   ],
   "source": [
    "print(f'The column names are :')\n",
    "print('#########')\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = df.filter(regex='nam').columns\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The #rows and #columns are  132  and  6\n",
      "The years in this dataset are:  [1973 1974 1975 1977 1978 1980 1982 1984 1986 1989 1991 1995 1993 1963\n",
      " 1964 1965 1966 1967 1968 1970 1976 1979 1981 2021 2012 2015 2017 2018\n",
      " 1999 2001 2003 2006 2009 2022 1969 1971 1972 1983 1987 1997 2002 2013\n",
      " 2016 1996 2000 2010 2014 2004 2005 2008 2019 2020 2024]\n",
      "The artists covered in this dataset are:  ['Queen', 'Nirvana', 'The Beatles', 'ABBA', 'Imagine Dragons', 'MUSE', 'Rosal√≠a', 'David Bowie', 'Spice Girls', 'Michael Jackson', 'Archive', 'Daft Punk', 'Taylor Swift']\n",
      "The genders covered are:  ['Rock', 'Pop', 'Pop Rock', 'Alternative Rock', 'Flamenco', 'Electronic']\n"
     ]
    }
   ],
   "source": [
    "print(\"The #rows and #columns are \", df.shape[0] , \" and \", df.shape[1])\n",
    "print(\"The years in this dataset are: \", df.year.unique())\n",
    "print(\"The artists covered in this dataset are: \", list(df.artist.unique()))\n",
    "print(\"The genders covered are: \", list(df.gender.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronic</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative Rock</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop Rock</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flamenco</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count\n",
       "gender                 \n",
       "Rock                 64\n",
       "Pop                  36\n",
       "Electronic           16\n",
       "Alternative Rock      9\n",
       "Pop Rock              4\n",
       "Flamenco              3"
      ]
     },
     "execution_count": 1152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.DataFrame({'Count':df.gender.value_counts()})\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alternative Rock</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronic</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flamenco</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop Rock</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count\n",
       "gender                 \n",
       "Alternative Rock      9\n",
       "Electronic           16\n",
       "Flamenco              3\n",
       "Pop                  36\n",
       "Pop Rock              4\n",
       "Rock                 64"
      ]
     },
     "execution_count": 1153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.sort_values(by=['gender'],ascending=True).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bought':'is_bought'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         0\n",
       "artist       0\n",
       "year         0\n",
       "gender       0\n",
       "likes        2\n",
       "is_bought    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         0\n",
       "artist       0\n",
       "year         0\n",
       "gender       0\n",
       "likes        0\n",
       "is_bought    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df.likes.isnull()]\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='is_bought', ylabel='count'>"
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'is_bought', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are :\n",
      "#########\n",
      "is_bought\n",
      "likes\n",
      "name\n",
      "artist\n",
      "year\n",
      "gender\n",
      "The column types are :\n",
      "#########\n",
      "bool\n",
      "float64\n",
      "category\n",
      "category\n",
      "category\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "data_orig = df.copy()\n",
    "data = df[['is_bought', 'likes','name', 'artist', 'year', 'gender']]\n",
    "categorical_columns  = ['name', 'artist', 'year','gender']\n",
    "for c in categorical_columns:\n",
    "    data[c] = data[c].astype('category')\n",
    "    \n",
    "print(f'The column names are :')\n",
    "print('#########')\n",
    "for col in data.columns:\n",
    "    print(col)\n",
    "\n",
    "print(f'The column types are :')\n",
    "print('#########')\n",
    "for col in data.dtypes:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j.pardo\\AppData\\Local\\Temp\\ipykernel_11648\\16605558.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_dummies = data_dummies.replace({True: 1, False: 0})\n"
     ]
    }
   ],
   "source": [
    "data_dummies = pd.get_dummies(data[categorical_columns], drop_first=True)\n",
    "data_dummies = data_dummies.replace({True: 1, False: 0})\n",
    "not_categorical_columns  = ['is_bought','likes']\n",
    "data = pd.concat([data, data_dummies], axis = 1)\n",
    "data.drop(categorical_columns,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The #rows and #columns are  130  and  197\n"
     ]
    }
   ],
   "source": [
    "print(\"The #rows and #columns are \", data.shape[0] , \" and \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are :\n",
      "#########\n",
      "is_bought\n",
      "likes\n",
      "name_1989\n",
      "name_A Hard Day's Night\n",
      "name_A Kind of Magic\n",
      "name_A Night at the Opera\n",
      "name_ABBA\n",
      "name_Abbey Road\n",
      "name_Absolution\n",
      "name_Aladdin Sane\n",
      "name_Arrival\n",
      "name_Axiom\n",
      "name_Bad\n",
      "name_Beatles '65\n",
      "name_Beatles VI\n",
      "name_Beatles for Sale\n",
      "name_Ben\n",
      "name_Black Holes and Revelations\n",
      "name_Black Tie White Noise\n",
      "name_Bleach\n",
      "name_Blood on the Dance Floor: History in the Mix\n",
      "name_Call to Arms and Angels\n",
      "name_Controlling Crowds\n",
      "name_Controlling Crowds ‚Äì Part IV\n",
      "name_Dangerous\n",
      "name_Diamond Dogs\n",
      "name_Discovery\n",
      "name_Drones\n",
      "name_Earthlinge\n",
      "name_El mal querer\n",
      "name_Evermore\n",
      "name_Fearless\n",
      "name_Folklore\n",
      "name_Forever\n",
      "name_Forever, Michael\n",
      "name_Got to Be There\n",
      "name_Heathen\n",
      "name_Help!\n",
      "name_History: Past, Present and Future, Book I\n",
      "name_Homework\n",
      "name_Hot Space\n",
      "name_Hours...\n",
      "name_Human After All\n",
      "name_Hunky Dory\n",
      "name_In Utero\n",
      "name_Innuendo\n",
      "name_Introducing... The Beatles\n",
      "name_Invincible\n",
      "name_Jazz\n",
      "name_Let It Be\n",
      "name_Let's Dance\n",
      "name_Lights \n",
      "name_Lodger\n",
      "name_Londinium\n",
      "name_Los √°ngeles\n",
      "name_Lover\n",
      "name_Low\n",
      "name_Made in Heaven\n",
      "name_Magical Mystery Tour\n",
      "name_Meet the Beatles!\n",
      "name_Mercury ‚Äì Act 1\n",
      "name_Michael\n",
      "name_Midnights\n",
      "name_Motomami\n",
      "name_Music and Me\n",
      "name_Never Let Me Down\n",
      "name_Nevermind\n",
      "name_News of the World\n",
      "name_Night Visions\n",
      "name_Noise\n",
      "name_Off the Wall\n",
      "name_Origin of Symmetry\n",
      "name_Origins\n",
      "name_Outside\n",
      "name_Pin Ups\n",
      "name_Please Please Me\n",
      "name_Queen\n",
      "name_Queen II\n",
      "name_Random Access Memories\n",
      "name_Reality\n",
      "name_Red\n",
      "name_Reputation\n",
      "name_Restriction\n",
      "name_Revolver \n",
      "name_Ring Ring\n",
      "name_Rubber Soul\n",
      "name_Scary Monsters (and Super Creeps)\n",
      "name_Sgt. Pepper's Lonely Hearts Club Band\n",
      "name_Sheer Heart Attack\n",
      "name_Showbiz\n",
      "name_Simulation Theory\n",
      "name_Smoke + Mirrors\n",
      "name_Something New\n",
      "name_Space Oddity\n",
      "name_Speak Now\n",
      "name_Spice\n",
      "name_Spiceworld\n",
      "name_Station to Station\n",
      "name_Super Trouper\n",
      "name_Take My Head\n",
      "name_Taylor Swift\n",
      "name_The 2nd Law\n",
      "name_The Album\n",
      "name_The BEATLES\n",
      "name_The Beatles' Second Album\n",
      "name_The Early Beatles\n",
      "name_The False Foundation\n",
      "name_The Game\n",
      "name_The Man Who Sold the World\n",
      "name_The Miracle\n",
      "name_The Next Day\n",
      "name_The Resistance\n",
      "name_The Rise and Fall of Ziggy Stardust and the Spiders from Mars\n",
      "name_The Visitors\n",
      "name_The Works\n",
      "name_Thriller\n",
      "name_Tonight\n",
      "name_Voulez-Vous\n",
      "name_Voyage\n",
      "name_Waterloo\n",
      "name_Will of the People\n",
      "name_With Us Until You're Dead \n",
      "name_With the Beatles\n",
      "name_Xscape\n",
      "name_Yellow Submarine\n",
      "name_Yesterday and Today\n",
      "name_You All Look the Same to Me  \n",
      "name_Young Americans\n",
      "name_‚òÖ\n",
      "artist_Archive\n",
      "artist_Daft Punk\n",
      "artist_David Bowie\n",
      "artist_Imagine Dragons\n",
      "artist_MUSE\n",
      "artist_Michael Jackson\n",
      "artist_Nirvana\n",
      "artist_Queen\n",
      "artist_Rosal√≠a\n",
      "artist_Spice Girls\n",
      "artist_Taylor Swift\n",
      "artist_The Beatles\n",
      "year_1964\n",
      "year_1965\n",
      "year_1966\n",
      "year_1967\n",
      "year_1968\n",
      "year_1969\n",
      "year_1970\n",
      "year_1971\n",
      "year_1972\n",
      "year_1973\n",
      "year_1974\n",
      "year_1975\n",
      "year_1976\n",
      "year_1977\n",
      "year_1978\n",
      "year_1979\n",
      "year_1980\n",
      "year_1981\n",
      "year_1982\n",
      "year_1983\n",
      "year_1984\n",
      "year_1986\n",
      "year_1987\n",
      "year_1989\n",
      "year_1991\n",
      "year_1993\n",
      "year_1995\n",
      "year_1996\n",
      "year_1997\n",
      "year_1999\n",
      "year_2000\n",
      "year_2001\n",
      "year_2002\n",
      "year_2003\n",
      "year_2004\n",
      "year_2005\n",
      "year_2006\n",
      "year_2008\n",
      "year_2009\n",
      "year_2010\n",
      "year_2012\n",
      "year_2013\n",
      "year_2014\n",
      "year_2015\n",
      "year_2016\n",
      "year_2017\n",
      "year_2018\n",
      "year_2019\n",
      "year_2020\n",
      "year_2021\n",
      "year_2022\n",
      "gender_Electronic\n",
      "gender_Flamenco\n",
      "gender_Pop\n",
      "gender_Pop Rock\n",
      "gender_Rock\n"
     ]
    }
   ],
   "source": [
    "print(f'The column names are :')\n",
    "print('#########')\n",
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'is_bought':'target'}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['likes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "Y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_of_epochs = 1000\n",
    "learning_rate=0.01\n",
    "weight_decay=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self, X: np.ndarray, y: np.ndarray) -> None:  \n",
    "    self.X = torch.from_numpy(X.astype(np.float32))\n",
    "    self.y = torch.from_numpy(y.astype(np.float32))\n",
    "    self.len = self.X.shape[0]\n",
    "\n",
    "  def __getitem__(self, index: int) -> tuple:\n",
    "    return self.X[index], self.y[index]\n",
    "  \n",
    "  def __len__(self) -> int:\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(self, train:Data, test:Data) -> None:\n",
    "        self.train = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        self.test = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Data(X_train.values, y_train.values)\n",
    "testdata = Data(X_test.values, y_test.values)\n",
    "\n",
    "loader = Loader(traindata, testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module): # all the dependencies from torch will be given to this class [parent class] # nn.Module contains all the building block of neural networks:\n",
    "  def __init__(self,input_dim):\n",
    "    super(LinearRegression,self).__init__()   # building connection with parent and child classes\n",
    "    self.fc1=nn.Linear(input_dim,10)          # hidden layer 1\n",
    "    self.fc2=nn.Linear(10,5)                  # hidden layer 2\n",
    "    self.fc3=nn.Linear(5,3)                   # hidden layer 3\n",
    "    self.fc4=nn.Linear(3,1)                   # last layer\n",
    "\n",
    "  def forward(self,d):\n",
    "    out=torch.relu(self.fc1(d))              # input * weights + bias for layer 1\n",
    "    out=torch.relu(self.fc2(out))            # input * weights + bias for layer 2\n",
    "    out=torch.relu(self.fc3(out))            # input * weights + bias for layer 3\n",
    "    out=self.fc4(out)                        # input * weights + bias for last layer\n",
    "    return out                               # final outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "torch.manual_seed(42)  # to make initilized weights stable:\n",
    "model = LinearRegression(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function with Classification Mean Squared Error loss and an optimizer with Adam optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizers=optim.Adam(params=model.parameters(),lr=learning_rate, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model \n",
    "def save() -> None:\n",
    "    filename=Path('saved')\n",
    "    filename.mkdir(parents=True,exist_ok=True)    \n",
    "    model_name='Network.pth' \n",
    "\n",
    "    saving_path=filename/model_name   \n",
    "    torch.save(obj=model.state_dict(),f=saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Convert to ONNX \n",
    "def export(): \n",
    "\n",
    "    # set the model to inference mode \n",
    "    model.eval() \n",
    "\n",
    "    # Let's create a dummy input tensor  \n",
    "    dummy_input = torch.randn(1)  \n",
    "\n",
    "    # Export the model   \n",
    "    torch.onnx.export(model,         # model being run \n",
    "         dummy_input,       # model input (or a tuple for multiple inputs) \n",
    "         \"saved/Network.onnx\",       # where to save the model  \n",
    "         export_params=True,  # store the trained parameter weights inside the model file \n",
    "         opset_version=11,    # the ONNX version to export the model to \n",
    "         do_constant_folding=True,  # whether to execute constant folding for optimization \n",
    "         input_names = ['input'],   # the model's input names \n",
    "         output_names = ['output'], # the model's output names \n",
    "         dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes \n",
    "                                'output' : {0 : 'batch_size'}}) \n",
    "    print(\" \") \n",
    "    print('Model has been converted to ONNX') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect() -> None:\n",
    "    # Let's create a dummy input tensor  \n",
    "    dummy_input = torch.randn(1)  \n",
    "\n",
    "    # we can inspect the model using TensorBoard\n",
    "    writer.add_graph(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def test() -> None:\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader.test:\n",
    "            inputs, targets = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(inputs)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            accuracy += (predicted == targets).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_of_epochs) -> None:\n",
    "\n",
    "  best_accuracy = 0.0\n",
    "\n",
    "  # Define your execution device\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(\"The model will be running on\", device, \"device\")\n",
    "\n",
    "  model.to(device)\n",
    "\n",
    "  # loop over the dataset multiple times\n",
    "  for epoch in range(num_of_epochs):\n",
    "\n",
    "    running_loss = 0.0     \n",
    "   \n",
    "    for i, data in enumerate(loader.train, 0):  \n",
    "       # get the inputs\n",
    "      inputs, targets = data\n",
    "      inputs, targets = inputs.float(), targets.float()\n",
    "      targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizers.zero_grad()\n",
    "      # predict classes using records from the training set\n",
    "      outputs=model(inputs) \n",
    "      # compute the loss based on model output and real targets\n",
    "      loss_value=loss(outputs, targets)      \n",
    "\n",
    "      #writer.add_scalar(\"Loss/train\", loss_value, epoch)     \n",
    "\n",
    "      # backpropagate the loss\n",
    "      loss_value.backward()  \n",
    "      # adjust parameters based on the calculated gradients\n",
    "      optimizers.step() \n",
    "\n",
    "      # Let's print statistics for every 10 records\n",
    "      running_loss += loss_value.item()     \n",
    "     \n",
    "      if i % 9 == 8:         \n",
    "\n",
    "        # ...log the running loss\n",
    "        writer.add_scalar('training loss',\n",
    "                            running_loss / 9,\n",
    "                            epoch * len(loader.train) + i)      \n",
    "          \n",
    "       # print every 9 (once per epoch) \n",
    "        print('[%d, %5d] loss: %.3f' % (epoch, i , running_loss / num_of_epochs))\n",
    "        # zero the loss\n",
    "        running_loss = 0.0      \n",
    "     \n",
    "\n",
    "    # Compute and print the average accuracy fo this epoch when tested over all test records\n",
    "    accuracy = test()\n",
    "    print('For epoch', epoch,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "      \n",
    "      # we want to save the model if the accuracy is the best\n",
    "    if accuracy > best_accuracy:\n",
    "        save()     \n",
    "        best_accuracy = accuracy  \n",
    "\n",
    "  writer.flush()\n",
    "\n",
    "  print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cpu device\n",
      "[0,     8] loss: 1.039\n",
      "For epoch 0 the test accuracy over the whole test set is 37 %\n",
      "[1,     8] loss: 0.002\n",
      "For epoch 1 the test accuracy over the whole test set is 37 %\n",
      "[2,     8] loss: 0.002\n",
      "For epoch 2 the test accuracy over the whole test set is 37 %\n",
      "[3,     8] loss: 0.002\n",
      "For epoch 3 the test accuracy over the whole test set is 37 %\n",
      "[4,     8] loss: 0.002\n",
      "For epoch 4 the test accuracy over the whole test set is 37 %\n",
      "[5,     8] loss: 0.002\n",
      "For epoch 5 the test accuracy over the whole test set is 37 %\n",
      "[6,     8] loss: 0.002\n",
      "For epoch 6 the test accuracy over the whole test set is 37 %\n",
      "[7,     8] loss: 0.002\n",
      "For epoch 7 the test accuracy over the whole test set is 37 %\n",
      "[8,     8] loss: 0.002\n",
      "For epoch 8 the test accuracy over the whole test set is 37 %\n",
      "[9,     8] loss: 0.002\n",
      "For epoch 9 the test accuracy over the whole test set is 37 %\n",
      "[10,     8] loss: 0.002\n",
      "For epoch 10 the test accuracy over the whole test set is 37 %\n",
      "[11,     8] loss: 0.002\n",
      "For epoch 11 the test accuracy over the whole test set is 37 %\n",
      "[12,     8] loss: 0.002\n",
      "For epoch 12 the test accuracy over the whole test set is 37 %\n",
      "[13,     8] loss: 0.002\n",
      "For epoch 13 the test accuracy over the whole test set is 37 %\n",
      "[14,     8] loss: 0.002\n",
      "For epoch 14 the test accuracy over the whole test set is 37 %\n",
      "[15,     8] loss: 0.002\n",
      "For epoch 15 the test accuracy over the whole test set is 37 %\n",
      "[16,     8] loss: 0.002\n",
      "For epoch 16 the test accuracy over the whole test set is 37 %\n",
      "[17,     8] loss: 0.002\n",
      "For epoch 17 the test accuracy over the whole test set is 37 %\n",
      "[18,     8] loss: 0.002\n",
      "For epoch 18 the test accuracy over the whole test set is 37 %\n",
      "[19,     8] loss: 0.002\n",
      "For epoch 19 the test accuracy over the whole test set is 37 %\n",
      "[20,     8] loss: 0.002\n",
      "For epoch 20 the test accuracy over the whole test set is 37 %\n",
      "[21,     8] loss: 0.002\n",
      "For epoch 21 the test accuracy over the whole test set is 37 %\n",
      "[22,     8] loss: 0.002\n",
      "For epoch 22 the test accuracy over the whole test set is 37 %\n",
      "[23,     8] loss: 0.002\n",
      "For epoch 23 the test accuracy over the whole test set is 37 %\n",
      "[24,     8] loss: 0.002\n",
      "For epoch 24 the test accuracy over the whole test set is 37 %\n",
      "[25,     8] loss: 0.002\n",
      "For epoch 25 the test accuracy over the whole test set is 37 %\n",
      "[26,     8] loss: 0.002\n",
      "For epoch 26 the test accuracy over the whole test set is 37 %\n",
      "[27,     8] loss: 0.002\n",
      "For epoch 27 the test accuracy over the whole test set is 37 %\n",
      "[28,     8] loss: 0.002\n",
      "For epoch 28 the test accuracy over the whole test set is 37 %\n",
      "[29,     8] loss: 0.002\n",
      "For epoch 29 the test accuracy over the whole test set is 37 %\n",
      "[30,     8] loss: 0.002\n",
      "For epoch 30 the test accuracy over the whole test set is 37 %\n",
      "[31,     8] loss: 0.002\n",
      "For epoch 31 the test accuracy over the whole test set is 37 %\n",
      "[32,     8] loss: 0.002\n",
      "For epoch 32 the test accuracy over the whole test set is 37 %\n",
      "[33,     8] loss: 0.002\n",
      "For epoch 33 the test accuracy over the whole test set is 37 %\n",
      "[34,     8] loss: 0.002\n",
      "For epoch 34 the test accuracy over the whole test set is 37 %\n",
      "[35,     8] loss: 0.002\n",
      "For epoch 35 the test accuracy over the whole test set is 37 %\n",
      "[36,     8] loss: 0.002\n",
      "For epoch 36 the test accuracy over the whole test set is 37 %\n",
      "[37,     8] loss: 0.002\n",
      "For epoch 37 the test accuracy over the whole test set is 37 %\n",
      "[38,     8] loss: 0.002\n",
      "For epoch 38 the test accuracy over the whole test set is 37 %\n",
      "[39,     8] loss: 0.002\n",
      "For epoch 39 the test accuracy over the whole test set is 37 %\n",
      "[40,     8] loss: 0.002\n",
      "For epoch 40 the test accuracy over the whole test set is 37 %\n",
      "[41,     8] loss: 0.002\n",
      "For epoch 41 the test accuracy over the whole test set is 37 %\n",
      "[42,     8] loss: 0.002\n",
      "For epoch 42 the test accuracy over the whole test set is 37 %\n",
      "[43,     8] loss: 0.002\n",
      "For epoch 43 the test accuracy over the whole test set is 37 %\n",
      "[44,     8] loss: 0.002\n",
      "For epoch 44 the test accuracy over the whole test set is 37 %\n",
      "[45,     8] loss: 0.002\n",
      "For epoch 45 the test accuracy over the whole test set is 37 %\n",
      "[46,     8] loss: 0.002\n",
      "For epoch 46 the test accuracy over the whole test set is 37 %\n",
      "[47,     8] loss: 0.002\n",
      "For epoch 47 the test accuracy over the whole test set is 37 %\n",
      "[48,     8] loss: 0.002\n",
      "For epoch 48 the test accuracy over the whole test set is 37 %\n",
      "[49,     8] loss: 0.002\n",
      "For epoch 49 the test accuracy over the whole test set is 37 %\n",
      "[50,     8] loss: 0.002\n",
      "For epoch 50 the test accuracy over the whole test set is 37 %\n",
      "[51,     8] loss: 0.002\n",
      "For epoch 51 the test accuracy over the whole test set is 37 %\n",
      "[52,     8] loss: 0.002\n",
      "For epoch 52 the test accuracy over the whole test set is 37 %\n",
      "[53,     8] loss: 0.002\n",
      "For epoch 53 the test accuracy over the whole test set is 37 %\n",
      "[54,     8] loss: 0.002\n",
      "For epoch 54 the test accuracy over the whole test set is 37 %\n",
      "[55,     8] loss: 0.002\n",
      "For epoch 55 the test accuracy over the whole test set is 37 %\n",
      "[56,     8] loss: 0.002\n",
      "For epoch 56 the test accuracy over the whole test set is 37 %\n",
      "[57,     8] loss: 0.002\n",
      "For epoch 57 the test accuracy over the whole test set is 37 %\n",
      "[58,     8] loss: 0.002\n",
      "For epoch 58 the test accuracy over the whole test set is 37 %\n",
      "[59,     8] loss: 0.002\n",
      "For epoch 59 the test accuracy over the whole test set is 37 %\n",
      "[60,     8] loss: 0.002\n",
      "For epoch 60 the test accuracy over the whole test set is 37 %\n",
      "[61,     8] loss: 0.002\n",
      "For epoch 61 the test accuracy over the whole test set is 37 %\n",
      "[62,     8] loss: 0.002\n",
      "For epoch 62 the test accuracy over the whole test set is 37 %\n",
      "[63,     8] loss: 0.002\n",
      "For epoch 63 the test accuracy over the whole test set is 37 %\n",
      "[64,     8] loss: 0.002\n",
      "For epoch 64 the test accuracy over the whole test set is 37 %\n",
      "[65,     8] loss: 0.002\n",
      "For epoch 65 the test accuracy over the whole test set is 37 %\n",
      "[66,     8] loss: 0.002\n",
      "For epoch 66 the test accuracy over the whole test set is 37 %\n",
      "[67,     8] loss: 0.002\n",
      "For epoch 67 the test accuracy over the whole test set is 37 %\n",
      "[68,     8] loss: 0.002\n",
      "For epoch 68 the test accuracy over the whole test set is 37 %\n",
      "[69,     8] loss: 0.002\n",
      "For epoch 69 the test accuracy over the whole test set is 37 %\n",
      "[70,     8] loss: 0.002\n",
      "For epoch 70 the test accuracy over the whole test set is 37 %\n",
      "[71,     8] loss: 0.002\n",
      "For epoch 71 the test accuracy over the whole test set is 37 %\n",
      "[72,     8] loss: 0.002\n",
      "For epoch 72 the test accuracy over the whole test set is 37 %\n",
      "[73,     8] loss: 0.002\n",
      "For epoch 73 the test accuracy over the whole test set is 37 %\n",
      "[74,     8] loss: 0.002\n",
      "For epoch 74 the test accuracy over the whole test set is 37 %\n",
      "[75,     8] loss: 0.002\n",
      "For epoch 75 the test accuracy over the whole test set is 37 %\n",
      "[76,     8] loss: 0.002\n",
      "For epoch 76 the test accuracy over the whole test set is 37 %\n",
      "[77,     8] loss: 0.002\n",
      "For epoch 77 the test accuracy over the whole test set is 37 %\n",
      "[78,     8] loss: 0.002\n",
      "For epoch 78 the test accuracy over the whole test set is 37 %\n",
      "[79,     8] loss: 0.002\n",
      "For epoch 79 the test accuracy over the whole test set is 37 %\n",
      "[80,     8] loss: 0.002\n",
      "For epoch 80 the test accuracy over the whole test set is 37 %\n",
      "[81,     8] loss: 0.002\n",
      "For epoch 81 the test accuracy over the whole test set is 37 %\n",
      "[82,     8] loss: 0.002\n",
      "For epoch 82 the test accuracy over the whole test set is 37 %\n",
      "[83,     8] loss: 0.002\n",
      "For epoch 83 the test accuracy over the whole test set is 37 %\n",
      "[84,     8] loss: 0.002\n",
      "For epoch 84 the test accuracy over the whole test set is 37 %\n",
      "[85,     8] loss: 0.002\n",
      "For epoch 85 the test accuracy over the whole test set is 37 %\n",
      "[86,     8] loss: 0.002\n",
      "For epoch 86 the test accuracy over the whole test set is 37 %\n",
      "[87,     8] loss: 0.002\n",
      "For epoch 87 the test accuracy over the whole test set is 37 %\n",
      "[88,     8] loss: 0.002\n",
      "For epoch 88 the test accuracy over the whole test set is 37 %\n",
      "[89,     8] loss: 0.002\n",
      "For epoch 89 the test accuracy over the whole test set is 37 %\n",
      "[90,     8] loss: 0.002\n",
      "For epoch 90 the test accuracy over the whole test set is 37 %\n",
      "[91,     8] loss: 0.002\n",
      "For epoch 91 the test accuracy over the whole test set is 37 %\n",
      "[92,     8] loss: 0.002\n",
      "For epoch 92 the test accuracy over the whole test set is 37 %\n",
      "[93,     8] loss: 0.002\n",
      "For epoch 93 the test accuracy over the whole test set is 37 %\n",
      "[94,     8] loss: 0.002\n",
      "For epoch 94 the test accuracy over the whole test set is 37 %\n",
      "[95,     8] loss: 0.002\n",
      "For epoch 95 the test accuracy over the whole test set is 37 %\n",
      "[96,     8] loss: 0.002\n",
      "For epoch 96 the test accuracy over the whole test set is 37 %\n",
      "[97,     8] loss: 0.002\n",
      "For epoch 97 the test accuracy over the whole test set is 37 %\n",
      "[98,     8] loss: 0.002\n",
      "For epoch 98 the test accuracy over the whole test set is 37 %\n",
      "[99,     8] loss: 0.002\n",
      "For epoch 99 the test accuracy over the whole test set is 37 %\n",
      "[100,     8] loss: 0.002\n",
      "For epoch 100 the test accuracy over the whole test set is 37 %\n",
      "[101,     8] loss: 0.002\n",
      "For epoch 101 the test accuracy over the whole test set is 37 %\n",
      "[102,     8] loss: 0.002\n",
      "For epoch 102 the test accuracy over the whole test set is 37 %\n",
      "[103,     8] loss: 0.002\n",
      "For epoch 103 the test accuracy over the whole test set is 37 %\n",
      "[104,     8] loss: 0.002\n",
      "For epoch 104 the test accuracy over the whole test set is 37 %\n",
      "[105,     8] loss: 0.002\n",
      "For epoch 105 the test accuracy over the whole test set is 37 %\n",
      "[106,     8] loss: 0.002\n",
      "For epoch 106 the test accuracy over the whole test set is 37 %\n",
      "[107,     8] loss: 0.002\n",
      "For epoch 107 the test accuracy over the whole test set is 37 %\n",
      "[108,     8] loss: 0.002\n",
      "For epoch 108 the test accuracy over the whole test set is 37 %\n",
      "[109,     8] loss: 0.002\n",
      "For epoch 109 the test accuracy over the whole test set is 37 %\n",
      "[110,     8] loss: 0.002\n",
      "For epoch 110 the test accuracy over the whole test set is 37 %\n",
      "[111,     8] loss: 0.002\n",
      "For epoch 111 the test accuracy over the whole test set is 37 %\n",
      "[112,     8] loss: 0.002\n",
      "For epoch 112 the test accuracy over the whole test set is 37 %\n",
      "[113,     8] loss: 0.002\n",
      "For epoch 113 the test accuracy over the whole test set is 37 %\n",
      "[114,     8] loss: 0.002\n",
      "For epoch 114 the test accuracy over the whole test set is 37 %\n",
      "[115,     8] loss: 0.002\n",
      "For epoch 115 the test accuracy over the whole test set is 37 %\n",
      "[116,     8] loss: 0.002\n",
      "For epoch 116 the test accuracy over the whole test set is 37 %\n",
      "[117,     8] loss: 0.002\n",
      "For epoch 117 the test accuracy over the whole test set is 37 %\n",
      "[118,     8] loss: 0.002\n",
      "For epoch 118 the test accuracy over the whole test set is 37 %\n",
      "[119,     8] loss: 0.002\n",
      "For epoch 119 the test accuracy over the whole test set is 37 %\n",
      "[120,     8] loss: 0.002\n",
      "For epoch 120 the test accuracy over the whole test set is 37 %\n",
      "[121,     8] loss: 0.002\n",
      "For epoch 121 the test accuracy over the whole test set is 37 %\n",
      "[122,     8] loss: 0.002\n",
      "For epoch 122 the test accuracy over the whole test set is 37 %\n",
      "[123,     8] loss: 0.002\n",
      "For epoch 123 the test accuracy over the whole test set is 37 %\n",
      "[124,     8] loss: 0.002\n",
      "For epoch 124 the test accuracy over the whole test set is 37 %\n",
      "[125,     8] loss: 0.002\n",
      "For epoch 125 the test accuracy over the whole test set is 37 %\n",
      "[126,     8] loss: 0.002\n",
      "For epoch 126 the test accuracy over the whole test set is 37 %\n",
      "[127,     8] loss: 0.002\n",
      "For epoch 127 the test accuracy over the whole test set is 37 %\n",
      "[128,     8] loss: 0.002\n",
      "For epoch 128 the test accuracy over the whole test set is 37 %\n",
      "[129,     8] loss: 0.002\n",
      "For epoch 129 the test accuracy over the whole test set is 37 %\n",
      "[130,     8] loss: 0.002\n",
      "For epoch 130 the test accuracy over the whole test set is 37 %\n",
      "[131,     8] loss: 0.002\n",
      "For epoch 131 the test accuracy over the whole test set is 37 %\n",
      "[132,     8] loss: 0.002\n",
      "For epoch 132 the test accuracy over the whole test set is 37 %\n",
      "[133,     8] loss: 0.002\n",
      "For epoch 133 the test accuracy over the whole test set is 37 %\n",
      "[134,     8] loss: 0.002\n",
      "For epoch 134 the test accuracy over the whole test set is 37 %\n",
      "[135,     8] loss: 0.002\n",
      "For epoch 135 the test accuracy over the whole test set is 37 %\n",
      "[136,     8] loss: 0.002\n",
      "For epoch 136 the test accuracy over the whole test set is 37 %\n",
      "[137,     8] loss: 0.002\n",
      "For epoch 137 the test accuracy over the whole test set is 37 %\n",
      "[138,     8] loss: 0.002\n",
      "For epoch 138 the test accuracy over the whole test set is 37 %\n",
      "[139,     8] loss: 0.002\n",
      "For epoch 139 the test accuracy over the whole test set is 37 %\n",
      "[140,     8] loss: 0.002\n",
      "For epoch 140 the test accuracy over the whole test set is 37 %\n",
      "[141,     8] loss: 0.002\n",
      "For epoch 141 the test accuracy over the whole test set is 37 %\n",
      "[142,     8] loss: 0.002\n",
      "For epoch 142 the test accuracy over the whole test set is 37 %\n",
      "[143,     8] loss: 0.002\n",
      "For epoch 143 the test accuracy over the whole test set is 37 %\n",
      "[144,     8] loss: 0.002\n",
      "For epoch 144 the test accuracy over the whole test set is 37 %\n",
      "[145,     8] loss: 0.002\n",
      "For epoch 145 the test accuracy over the whole test set is 37 %\n",
      "[146,     8] loss: 0.002\n",
      "For epoch 146 the test accuracy over the whole test set is 37 %\n",
      "[147,     8] loss: 0.002\n",
      "For epoch 147 the test accuracy over the whole test set is 37 %\n",
      "[148,     8] loss: 0.002\n",
      "For epoch 148 the test accuracy over the whole test set is 37 %\n",
      "[149,     8] loss: 0.002\n",
      "For epoch 149 the test accuracy over the whole test set is 37 %\n",
      "[150,     8] loss: 0.002\n",
      "For epoch 150 the test accuracy over the whole test set is 37 %\n",
      "[151,     8] loss: 0.002\n",
      "For epoch 151 the test accuracy over the whole test set is 37 %\n",
      "[152,     8] loss: 0.002\n",
      "For epoch 152 the test accuracy over the whole test set is 37 %\n",
      "[153,     8] loss: 0.002\n",
      "For epoch 153 the test accuracy over the whole test set is 37 %\n",
      "[154,     8] loss: 0.002\n",
      "For epoch 154 the test accuracy over the whole test set is 37 %\n",
      "[155,     8] loss: 0.002\n",
      "For epoch 155 the test accuracy over the whole test set is 37 %\n",
      "[156,     8] loss: 0.002\n",
      "For epoch 156 the test accuracy over the whole test set is 37 %\n",
      "[157,     8] loss: 0.002\n",
      "For epoch 157 the test accuracy over the whole test set is 37 %\n",
      "[158,     8] loss: 0.002\n",
      "For epoch 158 the test accuracy over the whole test set is 37 %\n",
      "[159,     8] loss: 0.002\n",
      "For epoch 159 the test accuracy over the whole test set is 37 %\n",
      "[160,     8] loss: 0.002\n",
      "For epoch 160 the test accuracy over the whole test set is 37 %\n",
      "[161,     8] loss: 0.002\n",
      "For epoch 161 the test accuracy over the whole test set is 37 %\n",
      "[162,     8] loss: 0.002\n",
      "For epoch 162 the test accuracy over the whole test set is 37 %\n",
      "[163,     8] loss: 0.002\n",
      "For epoch 163 the test accuracy over the whole test set is 37 %\n",
      "[164,     8] loss: 0.002\n",
      "For epoch 164 the test accuracy over the whole test set is 37 %\n",
      "[165,     8] loss: 0.002\n",
      "For epoch 165 the test accuracy over the whole test set is 37 %\n",
      "[166,     8] loss: 0.002\n",
      "For epoch 166 the test accuracy over the whole test set is 37 %\n",
      "[167,     8] loss: 0.002\n",
      "For epoch 167 the test accuracy over the whole test set is 37 %\n",
      "[168,     8] loss: 0.002\n",
      "For epoch 168 the test accuracy over the whole test set is 37 %\n",
      "[169,     8] loss: 0.002\n",
      "For epoch 169 the test accuracy over the whole test set is 37 %\n",
      "[170,     8] loss: 0.002\n",
      "For epoch 170 the test accuracy over the whole test set is 37 %\n",
      "[171,     8] loss: 0.002\n",
      "For epoch 171 the test accuracy over the whole test set is 37 %\n",
      "[172,     8] loss: 0.002\n",
      "For epoch 172 the test accuracy over the whole test set is 37 %\n",
      "[173,     8] loss: 0.002\n",
      "For epoch 173 the test accuracy over the whole test set is 37 %\n",
      "[174,     8] loss: 0.002\n",
      "For epoch 174 the test accuracy over the whole test set is 37 %\n",
      "[175,     8] loss: 0.002\n",
      "For epoch 175 the test accuracy over the whole test set is 37 %\n",
      "[176,     8] loss: 0.002\n",
      "For epoch 176 the test accuracy over the whole test set is 37 %\n",
      "[177,     8] loss: 0.002\n",
      "For epoch 177 the test accuracy over the whole test set is 37 %\n",
      "[178,     8] loss: 0.002\n",
      "For epoch 178 the test accuracy over the whole test set is 37 %\n",
      "[179,     8] loss: 0.002\n",
      "For epoch 179 the test accuracy over the whole test set is 37 %\n",
      "[180,     8] loss: 0.002\n",
      "For epoch 180 the test accuracy over the whole test set is 37 %\n",
      "[181,     8] loss: 0.002\n",
      "For epoch 181 the test accuracy over the whole test set is 37 %\n",
      "[182,     8] loss: 0.002\n",
      "For epoch 182 the test accuracy over the whole test set is 37 %\n",
      "[183,     8] loss: 0.002\n",
      "For epoch 183 the test accuracy over the whole test set is 37 %\n",
      "[184,     8] loss: 0.002\n",
      "For epoch 184 the test accuracy over the whole test set is 37 %\n",
      "[185,     8] loss: 0.002\n",
      "For epoch 185 the test accuracy over the whole test set is 37 %\n",
      "[186,     8] loss: 0.002\n",
      "For epoch 186 the test accuracy over the whole test set is 37 %\n",
      "[187,     8] loss: 0.002\n",
      "For epoch 187 the test accuracy over the whole test set is 37 %\n",
      "[188,     8] loss: 0.002\n",
      "For epoch 188 the test accuracy over the whole test set is 37 %\n",
      "[189,     8] loss: 0.002\n",
      "For epoch 189 the test accuracy over the whole test set is 37 %\n",
      "[190,     8] loss: 0.002\n",
      "For epoch 190 the test accuracy over the whole test set is 37 %\n",
      "[191,     8] loss: 0.002\n",
      "For epoch 191 the test accuracy over the whole test set is 37 %\n",
      "[192,     8] loss: 0.002\n",
      "For epoch 192 the test accuracy over the whole test set is 37 %\n",
      "[193,     8] loss: 0.002\n",
      "For epoch 193 the test accuracy over the whole test set is 37 %\n",
      "[194,     8] loss: 0.002\n",
      "For epoch 194 the test accuracy over the whole test set is 37 %\n",
      "[195,     8] loss: 0.002\n",
      "For epoch 195 the test accuracy over the whole test set is 37 %\n",
      "[196,     8] loss: 0.002\n",
      "For epoch 196 the test accuracy over the whole test set is 37 %\n",
      "[197,     8] loss: 0.002\n",
      "For epoch 197 the test accuracy over the whole test set is 37 %\n",
      "[198,     8] loss: 0.002\n",
      "For epoch 198 the test accuracy over the whole test set is 37 %\n",
      "[199,     8] loss: 0.002\n",
      "For epoch 199 the test accuracy over the whole test set is 37 %\n",
      "[200,     8] loss: 0.002\n",
      "For epoch 200 the test accuracy over the whole test set is 37 %\n",
      "[201,     8] loss: 0.002\n",
      "For epoch 201 the test accuracy over the whole test set is 37 %\n",
      "[202,     8] loss: 0.002\n",
      "For epoch 202 the test accuracy over the whole test set is 37 %\n",
      "[203,     8] loss: 0.002\n",
      "For epoch 203 the test accuracy over the whole test set is 37 %\n",
      "[204,     8] loss: 0.002\n",
      "For epoch 204 the test accuracy over the whole test set is 37 %\n",
      "[205,     8] loss: 0.002\n",
      "For epoch 205 the test accuracy over the whole test set is 37 %\n",
      "[206,     8] loss: 0.002\n",
      "For epoch 206 the test accuracy over the whole test set is 37 %\n",
      "[207,     8] loss: 0.002\n",
      "For epoch 207 the test accuracy over the whole test set is 37 %\n",
      "[208,     8] loss: 0.002\n",
      "For epoch 208 the test accuracy over the whole test set is 37 %\n",
      "[209,     8] loss: 0.002\n",
      "For epoch 209 the test accuracy over the whole test set is 37 %\n",
      "[210,     8] loss: 0.002\n",
      "For epoch 210 the test accuracy over the whole test set is 37 %\n",
      "[211,     8] loss: 0.002\n",
      "For epoch 211 the test accuracy over the whole test set is 37 %\n",
      "[212,     8] loss: 0.002\n",
      "For epoch 212 the test accuracy over the whole test set is 37 %\n",
      "[213,     8] loss: 0.002\n",
      "For epoch 213 the test accuracy over the whole test set is 37 %\n",
      "[214,     8] loss: 0.002\n",
      "For epoch 214 the test accuracy over the whole test set is 37 %\n",
      "[215,     8] loss: 0.002\n",
      "For epoch 215 the test accuracy over the whole test set is 37 %\n",
      "[216,     8] loss: 0.002\n",
      "For epoch 216 the test accuracy over the whole test set is 37 %\n",
      "[217,     8] loss: 0.002\n",
      "For epoch 217 the test accuracy over the whole test set is 37 %\n",
      "[218,     8] loss: 0.002\n",
      "For epoch 218 the test accuracy over the whole test set is 37 %\n",
      "[219,     8] loss: 0.002\n",
      "For epoch 219 the test accuracy over the whole test set is 37 %\n",
      "[220,     8] loss: 0.002\n",
      "For epoch 220 the test accuracy over the whole test set is 37 %\n",
      "[221,     8] loss: 0.002\n",
      "For epoch 221 the test accuracy over the whole test set is 37 %\n",
      "[222,     8] loss: 0.002\n",
      "For epoch 222 the test accuracy over the whole test set is 37 %\n",
      "[223,     8] loss: 0.002\n",
      "For epoch 223 the test accuracy over the whole test set is 37 %\n",
      "[224,     8] loss: 0.002\n",
      "For epoch 224 the test accuracy over the whole test set is 37 %\n",
      "[225,     8] loss: 0.002\n",
      "For epoch 225 the test accuracy over the whole test set is 37 %\n",
      "[226,     8] loss: 0.002\n",
      "For epoch 226 the test accuracy over the whole test set is 37 %\n",
      "[227,     8] loss: 0.002\n",
      "For epoch 227 the test accuracy over the whole test set is 37 %\n",
      "[228,     8] loss: 0.002\n",
      "For epoch 228 the test accuracy over the whole test set is 37 %\n",
      "[229,     8] loss: 0.002\n",
      "For epoch 229 the test accuracy over the whole test set is 37 %\n",
      "[230,     8] loss: 0.002\n",
      "For epoch 230 the test accuracy over the whole test set is 37 %\n",
      "[231,     8] loss: 0.002\n",
      "For epoch 231 the test accuracy over the whole test set is 37 %\n",
      "[232,     8] loss: 0.002\n",
      "For epoch 232 the test accuracy over the whole test set is 37 %\n",
      "[233,     8] loss: 0.002\n",
      "For epoch 233 the test accuracy over the whole test set is 37 %\n",
      "[234,     8] loss: 0.002\n",
      "For epoch 234 the test accuracy over the whole test set is 37 %\n",
      "[235,     8] loss: 0.002\n",
      "For epoch 235 the test accuracy over the whole test set is 37 %\n",
      "[236,     8] loss: 0.002\n",
      "For epoch 236 the test accuracy over the whole test set is 37 %\n",
      "[237,     8] loss: 0.002\n",
      "For epoch 237 the test accuracy over the whole test set is 37 %\n",
      "[238,     8] loss: 0.002\n",
      "For epoch 238 the test accuracy over the whole test set is 37 %\n",
      "[239,     8] loss: 0.002\n",
      "For epoch 239 the test accuracy over the whole test set is 37 %\n",
      "[240,     8] loss: 0.002\n",
      "For epoch 240 the test accuracy over the whole test set is 37 %\n",
      "[241,     8] loss: 0.002\n",
      "For epoch 241 the test accuracy over the whole test set is 37 %\n",
      "[242,     8] loss: 0.002\n",
      "For epoch 242 the test accuracy over the whole test set is 37 %\n",
      "[243,     8] loss: 0.002\n",
      "For epoch 243 the test accuracy over the whole test set is 37 %\n",
      "[244,     8] loss: 0.002\n",
      "For epoch 244 the test accuracy over the whole test set is 37 %\n",
      "[245,     8] loss: 0.002\n",
      "For epoch 245 the test accuracy over the whole test set is 37 %\n",
      "[246,     8] loss: 0.002\n",
      "For epoch 246 the test accuracy over the whole test set is 37 %\n",
      "[247,     8] loss: 0.002\n",
      "For epoch 247 the test accuracy over the whole test set is 37 %\n",
      "[248,     8] loss: 0.002\n",
      "For epoch 248 the test accuracy over the whole test set is 37 %\n",
      "[249,     8] loss: 0.002\n",
      "For epoch 249 the test accuracy over the whole test set is 37 %\n",
      "[250,     8] loss: 0.002\n",
      "For epoch 250 the test accuracy over the whole test set is 37 %\n",
      "[251,     8] loss: 0.002\n",
      "For epoch 251 the test accuracy over the whole test set is 37 %\n",
      "[252,     8] loss: 0.002\n",
      "For epoch 252 the test accuracy over the whole test set is 37 %\n",
      "[253,     8] loss: 0.002\n",
      "For epoch 253 the test accuracy over the whole test set is 37 %\n",
      "[254,     8] loss: 0.002\n",
      "For epoch 254 the test accuracy over the whole test set is 37 %\n",
      "[255,     8] loss: 0.002\n",
      "For epoch 255 the test accuracy over the whole test set is 37 %\n",
      "[256,     8] loss: 0.002\n",
      "For epoch 256 the test accuracy over the whole test set is 37 %\n",
      "[257,     8] loss: 0.002\n",
      "For epoch 257 the test accuracy over the whole test set is 37 %\n",
      "[258,     8] loss: 0.002\n",
      "For epoch 258 the test accuracy over the whole test set is 37 %\n",
      "[259,     8] loss: 0.002\n",
      "For epoch 259 the test accuracy over the whole test set is 37 %\n",
      "[260,     8] loss: 0.002\n",
      "For epoch 260 the test accuracy over the whole test set is 37 %\n",
      "[261,     8] loss: 0.002\n",
      "For epoch 261 the test accuracy over the whole test set is 37 %\n",
      "[262,     8] loss: 0.002\n",
      "For epoch 262 the test accuracy over the whole test set is 37 %\n",
      "[263,     8] loss: 0.002\n",
      "For epoch 263 the test accuracy over the whole test set is 37 %\n",
      "[264,     8] loss: 0.002\n",
      "For epoch 264 the test accuracy over the whole test set is 37 %\n",
      "[265,     8] loss: 0.002\n",
      "For epoch 265 the test accuracy over the whole test set is 37 %\n",
      "[266,     8] loss: 0.002\n",
      "For epoch 266 the test accuracy over the whole test set is 37 %\n",
      "[267,     8] loss: 0.002\n",
      "For epoch 267 the test accuracy over the whole test set is 37 %\n",
      "[268,     8] loss: 0.002\n",
      "For epoch 268 the test accuracy over the whole test set is 37 %\n",
      "[269,     8] loss: 0.002\n",
      "For epoch 269 the test accuracy over the whole test set is 37 %\n",
      "[270,     8] loss: 0.002\n",
      "For epoch 270 the test accuracy over the whole test set is 37 %\n",
      "[271,     8] loss: 0.002\n",
      "For epoch 271 the test accuracy over the whole test set is 37 %\n",
      "[272,     8] loss: 0.002\n",
      "For epoch 272 the test accuracy over the whole test set is 37 %\n",
      "[273,     8] loss: 0.002\n",
      "For epoch 273 the test accuracy over the whole test set is 37 %\n",
      "[274,     8] loss: 0.002\n",
      "For epoch 274 the test accuracy over the whole test set is 37 %\n",
      "[275,     8] loss: 0.002\n",
      "For epoch 275 the test accuracy over the whole test set is 37 %\n",
      "[276,     8] loss: 0.002\n",
      "For epoch 276 the test accuracy over the whole test set is 37 %\n",
      "[277,     8] loss: 0.002\n",
      "For epoch 277 the test accuracy over the whole test set is 37 %\n",
      "[278,     8] loss: 0.002\n",
      "For epoch 278 the test accuracy over the whole test set is 37 %\n",
      "[279,     8] loss: 0.002\n",
      "For epoch 279 the test accuracy over the whole test set is 37 %\n",
      "[280,     8] loss: 0.002\n",
      "For epoch 280 the test accuracy over the whole test set is 37 %\n",
      "[281,     8] loss: 0.002\n",
      "For epoch 281 the test accuracy over the whole test set is 37 %\n",
      "[282,     8] loss: 0.002\n",
      "For epoch 282 the test accuracy over the whole test set is 37 %\n",
      "[283,     8] loss: 0.002\n",
      "For epoch 283 the test accuracy over the whole test set is 37 %\n",
      "[284,     8] loss: 0.002\n",
      "For epoch 284 the test accuracy over the whole test set is 37 %\n",
      "[285,     8] loss: 0.002\n",
      "For epoch 285 the test accuracy over the whole test set is 37 %\n",
      "[286,     8] loss: 0.002\n",
      "For epoch 286 the test accuracy over the whole test set is 37 %\n",
      "[287,     8] loss: 0.002\n",
      "For epoch 287 the test accuracy over the whole test set is 37 %\n",
      "[288,     8] loss: 0.002\n",
      "For epoch 288 the test accuracy over the whole test set is 37 %\n",
      "[289,     8] loss: 0.002\n",
      "For epoch 289 the test accuracy over the whole test set is 37 %\n",
      "[290,     8] loss: 0.002\n",
      "For epoch 290 the test accuracy over the whole test set is 37 %\n",
      "[291,     8] loss: 0.002\n",
      "For epoch 291 the test accuracy over the whole test set is 37 %\n",
      "[292,     8] loss: 0.002\n",
      "For epoch 292 the test accuracy over the whole test set is 37 %\n",
      "[293,     8] loss: 0.002\n",
      "For epoch 293 the test accuracy over the whole test set is 37 %\n",
      "[294,     8] loss: 0.002\n",
      "For epoch 294 the test accuracy over the whole test set is 37 %\n",
      "[295,     8] loss: 0.002\n",
      "For epoch 295 the test accuracy over the whole test set is 37 %\n",
      "[296,     8] loss: 0.002\n",
      "For epoch 296 the test accuracy over the whole test set is 37 %\n",
      "[297,     8] loss: 0.002\n",
      "For epoch 297 the test accuracy over the whole test set is 37 %\n",
      "[298,     8] loss: 0.002\n",
      "For epoch 298 the test accuracy over the whole test set is 37 %\n",
      "[299,     8] loss: 0.002\n",
      "For epoch 299 the test accuracy over the whole test set is 37 %\n",
      "[300,     8] loss: 0.002\n",
      "For epoch 300 the test accuracy over the whole test set is 37 %\n",
      "[301,     8] loss: 0.002\n",
      "For epoch 301 the test accuracy over the whole test set is 37 %\n",
      "[302,     8] loss: 0.002\n",
      "For epoch 302 the test accuracy over the whole test set is 37 %\n",
      "[303,     8] loss: 0.002\n",
      "For epoch 303 the test accuracy over the whole test set is 37 %\n",
      "[304,     8] loss: 0.002\n",
      "For epoch 304 the test accuracy over the whole test set is 37 %\n",
      "[305,     8] loss: 0.002\n",
      "For epoch 305 the test accuracy over the whole test set is 37 %\n",
      "[306,     8] loss: 0.002\n",
      "For epoch 306 the test accuracy over the whole test set is 37 %\n",
      "[307,     8] loss: 0.002\n",
      "For epoch 307 the test accuracy over the whole test set is 37 %\n",
      "[308,     8] loss: 0.002\n",
      "For epoch 308 the test accuracy over the whole test set is 37 %\n",
      "[309,     8] loss: 0.002\n",
      "For epoch 309 the test accuracy over the whole test set is 37 %\n",
      "[310,     8] loss: 0.002\n",
      "For epoch 310 the test accuracy over the whole test set is 37 %\n",
      "[311,     8] loss: 0.002\n",
      "For epoch 311 the test accuracy over the whole test set is 37 %\n",
      "[312,     8] loss: 0.002\n",
      "For epoch 312 the test accuracy over the whole test set is 37 %\n",
      "[313,     8] loss: 0.002\n",
      "For epoch 313 the test accuracy over the whole test set is 37 %\n",
      "[314,     8] loss: 0.002\n",
      "For epoch 314 the test accuracy over the whole test set is 37 %\n",
      "[315,     8] loss: 0.002\n",
      "For epoch 315 the test accuracy over the whole test set is 37 %\n",
      "[316,     8] loss: 0.002\n",
      "For epoch 316 the test accuracy over the whole test set is 37 %\n",
      "[317,     8] loss: 0.002\n",
      "For epoch 317 the test accuracy over the whole test set is 37 %\n",
      "[318,     8] loss: 0.002\n",
      "For epoch 318 the test accuracy over the whole test set is 37 %\n",
      "[319,     8] loss: 0.002\n",
      "For epoch 319 the test accuracy over the whole test set is 37 %\n",
      "[320,     8] loss: 0.002\n",
      "For epoch 320 the test accuracy over the whole test set is 37 %\n",
      "[321,     8] loss: 0.002\n",
      "For epoch 321 the test accuracy over the whole test set is 37 %\n",
      "[322,     8] loss: 0.002\n",
      "For epoch 322 the test accuracy over the whole test set is 37 %\n",
      "[323,     8] loss: 0.002\n",
      "For epoch 323 the test accuracy over the whole test set is 37 %\n",
      "[324,     8] loss: 0.002\n",
      "For epoch 324 the test accuracy over the whole test set is 37 %\n",
      "[325,     8] loss: 0.002\n",
      "For epoch 325 the test accuracy over the whole test set is 37 %\n",
      "[326,     8] loss: 0.002\n",
      "For epoch 326 the test accuracy over the whole test set is 37 %\n",
      "[327,     8] loss: 0.002\n",
      "For epoch 327 the test accuracy over the whole test set is 37 %\n",
      "[328,     8] loss: 0.002\n",
      "For epoch 328 the test accuracy over the whole test set is 37 %\n",
      "[329,     8] loss: 0.002\n",
      "For epoch 329 the test accuracy over the whole test set is 37 %\n",
      "[330,     8] loss: 0.002\n",
      "For epoch 330 the test accuracy over the whole test set is 37 %\n",
      "[331,     8] loss: 0.002\n",
      "For epoch 331 the test accuracy over the whole test set is 37 %\n",
      "[332,     8] loss: 0.002\n",
      "For epoch 332 the test accuracy over the whole test set is 37 %\n",
      "[333,     8] loss: 0.002\n",
      "For epoch 333 the test accuracy over the whole test set is 37 %\n",
      "[334,     8] loss: 0.002\n",
      "For epoch 334 the test accuracy over the whole test set is 37 %\n",
      "[335,     8] loss: 0.002\n",
      "For epoch 335 the test accuracy over the whole test set is 37 %\n",
      "[336,     8] loss: 0.002\n",
      "For epoch 336 the test accuracy over the whole test set is 37 %\n",
      "[337,     8] loss: 0.002\n",
      "For epoch 337 the test accuracy over the whole test set is 37 %\n",
      "[338,     8] loss: 0.002\n",
      "For epoch 338 the test accuracy over the whole test set is 37 %\n",
      "[339,     8] loss: 0.002\n",
      "For epoch 339 the test accuracy over the whole test set is 37 %\n",
      "[340,     8] loss: 0.002\n",
      "For epoch 340 the test accuracy over the whole test set is 37 %\n",
      "[341,     8] loss: 0.002\n",
      "For epoch 341 the test accuracy over the whole test set is 37 %\n",
      "[342,     8] loss: 0.002\n",
      "For epoch 342 the test accuracy over the whole test set is 37 %\n",
      "[343,     8] loss: 0.002\n",
      "For epoch 343 the test accuracy over the whole test set is 37 %\n",
      "[344,     8] loss: 0.002\n",
      "For epoch 344 the test accuracy over the whole test set is 37 %\n",
      "[345,     8] loss: 0.002\n",
      "For epoch 345 the test accuracy over the whole test set is 37 %\n",
      "[346,     8] loss: 0.002\n",
      "For epoch 346 the test accuracy over the whole test set is 37 %\n",
      "[347,     8] loss: 0.002\n",
      "For epoch 347 the test accuracy over the whole test set is 37 %\n",
      "[348,     8] loss: 0.002\n",
      "For epoch 348 the test accuracy over the whole test set is 37 %\n",
      "[349,     8] loss: 0.002\n",
      "For epoch 349 the test accuracy over the whole test set is 37 %\n",
      "[350,     8] loss: 0.002\n",
      "For epoch 350 the test accuracy over the whole test set is 37 %\n",
      "[351,     8] loss: 0.002\n",
      "For epoch 351 the test accuracy over the whole test set is 37 %\n",
      "[352,     8] loss: 0.002\n",
      "For epoch 352 the test accuracy over the whole test set is 37 %\n",
      "[353,     8] loss: 0.002\n",
      "For epoch 353 the test accuracy over the whole test set is 37 %\n",
      "[354,     8] loss: 0.002\n",
      "For epoch 354 the test accuracy over the whole test set is 37 %\n",
      "[355,     8] loss: 0.002\n",
      "For epoch 355 the test accuracy over the whole test set is 37 %\n",
      "[356,     8] loss: 0.002\n",
      "For epoch 356 the test accuracy over the whole test set is 37 %\n",
      "[357,     8] loss: 0.002\n",
      "For epoch 357 the test accuracy over the whole test set is 37 %\n",
      "[358,     8] loss: 0.002\n",
      "For epoch 358 the test accuracy over the whole test set is 37 %\n",
      "[359,     8] loss: 0.002\n",
      "For epoch 359 the test accuracy over the whole test set is 37 %\n",
      "[360,     8] loss: 0.002\n",
      "For epoch 360 the test accuracy over the whole test set is 37 %\n",
      "[361,     8] loss: 0.002\n",
      "For epoch 361 the test accuracy over the whole test set is 37 %\n",
      "[362,     8] loss: 0.002\n",
      "For epoch 362 the test accuracy over the whole test set is 37 %\n",
      "[363,     8] loss: 0.002\n",
      "For epoch 363 the test accuracy over the whole test set is 37 %\n",
      "[364,     8] loss: 0.002\n",
      "For epoch 364 the test accuracy over the whole test set is 37 %\n",
      "[365,     8] loss: 0.002\n",
      "For epoch 365 the test accuracy over the whole test set is 37 %\n",
      "[366,     8] loss: 0.002\n",
      "For epoch 366 the test accuracy over the whole test set is 37 %\n",
      "[367,     8] loss: 0.002\n",
      "For epoch 367 the test accuracy over the whole test set is 37 %\n",
      "[368,     8] loss: 0.002\n",
      "For epoch 368 the test accuracy over the whole test set is 37 %\n",
      "[369,     8] loss: 0.002\n",
      "For epoch 369 the test accuracy over the whole test set is 37 %\n",
      "[370,     8] loss: 0.002\n",
      "For epoch 370 the test accuracy over the whole test set is 37 %\n",
      "[371,     8] loss: 0.002\n",
      "For epoch 371 the test accuracy over the whole test set is 37 %\n",
      "[372,     8] loss: 0.002\n",
      "For epoch 372 the test accuracy over the whole test set is 37 %\n",
      "[373,     8] loss: 0.002\n",
      "For epoch 373 the test accuracy over the whole test set is 37 %\n",
      "[374,     8] loss: 0.002\n",
      "For epoch 374 the test accuracy over the whole test set is 37 %\n",
      "[375,     8] loss: 0.002\n",
      "For epoch 375 the test accuracy over the whole test set is 37 %\n",
      "[376,     8] loss: 0.002\n",
      "For epoch 376 the test accuracy over the whole test set is 37 %\n",
      "[377,     8] loss: 0.002\n",
      "For epoch 377 the test accuracy over the whole test set is 37 %\n",
      "[378,     8] loss: 0.002\n",
      "For epoch 378 the test accuracy over the whole test set is 37 %\n",
      "[379,     8] loss: 0.002\n",
      "For epoch 379 the test accuracy over the whole test set is 37 %\n",
      "[380,     8] loss: 0.002\n",
      "For epoch 380 the test accuracy over the whole test set is 37 %\n",
      "[381,     8] loss: 0.002\n",
      "For epoch 381 the test accuracy over the whole test set is 37 %\n",
      "[382,     8] loss: 0.002\n",
      "For epoch 382 the test accuracy over the whole test set is 37 %\n",
      "[383,     8] loss: 0.002\n",
      "For epoch 383 the test accuracy over the whole test set is 37 %\n",
      "[384,     8] loss: 0.002\n",
      "For epoch 384 the test accuracy over the whole test set is 37 %\n",
      "[385,     8] loss: 0.002\n",
      "For epoch 385 the test accuracy over the whole test set is 37 %\n",
      "[386,     8] loss: 0.002\n",
      "For epoch 386 the test accuracy over the whole test set is 37 %\n",
      "[387,     8] loss: 0.002\n",
      "For epoch 387 the test accuracy over the whole test set is 37 %\n",
      "[388,     8] loss: 0.002\n",
      "For epoch 388 the test accuracy over the whole test set is 37 %\n",
      "[389,     8] loss: 0.002\n",
      "For epoch 389 the test accuracy over the whole test set is 37 %\n",
      "[390,     8] loss: 0.002\n",
      "For epoch 390 the test accuracy over the whole test set is 37 %\n",
      "[391,     8] loss: 0.002\n",
      "For epoch 391 the test accuracy over the whole test set is 37 %\n",
      "[392,     8] loss: 0.002\n",
      "For epoch 392 the test accuracy over the whole test set is 37 %\n",
      "[393,     8] loss: 0.002\n",
      "For epoch 393 the test accuracy over the whole test set is 37 %\n",
      "[394,     8] loss: 0.002\n",
      "For epoch 394 the test accuracy over the whole test set is 37 %\n",
      "[395,     8] loss: 0.002\n",
      "For epoch 395 the test accuracy over the whole test set is 37 %\n",
      "[396,     8] loss: 0.002\n",
      "For epoch 396 the test accuracy over the whole test set is 37 %\n",
      "[397,     8] loss: 0.002\n",
      "For epoch 397 the test accuracy over the whole test set is 37 %\n",
      "[398,     8] loss: 0.002\n",
      "For epoch 398 the test accuracy over the whole test set is 37 %\n",
      "[399,     8] loss: 0.002\n",
      "For epoch 399 the test accuracy over the whole test set is 37 %\n",
      "[400,     8] loss: 0.002\n",
      "For epoch 400 the test accuracy over the whole test set is 37 %\n",
      "[401,     8] loss: 0.002\n",
      "For epoch 401 the test accuracy over the whole test set is 37 %\n",
      "[402,     8] loss: 0.002\n",
      "For epoch 402 the test accuracy over the whole test set is 37 %\n",
      "[403,     8] loss: 0.002\n",
      "For epoch 403 the test accuracy over the whole test set is 37 %\n",
      "[404,     8] loss: 0.002\n",
      "For epoch 404 the test accuracy over the whole test set is 37 %\n",
      "[405,     8] loss: 0.002\n",
      "For epoch 405 the test accuracy over the whole test set is 37 %\n",
      "[406,     8] loss: 0.002\n",
      "For epoch 406 the test accuracy over the whole test set is 37 %\n",
      "[407,     8] loss: 0.002\n",
      "For epoch 407 the test accuracy over the whole test set is 37 %\n",
      "[408,     8] loss: 0.002\n",
      "For epoch 408 the test accuracy over the whole test set is 37 %\n",
      "[409,     8] loss: 0.002\n",
      "For epoch 409 the test accuracy over the whole test set is 37 %\n",
      "[410,     8] loss: 0.002\n",
      "For epoch 410 the test accuracy over the whole test set is 37 %\n",
      "[411,     8] loss: 0.002\n",
      "For epoch 411 the test accuracy over the whole test set is 37 %\n",
      "[412,     8] loss: 0.002\n",
      "For epoch 412 the test accuracy over the whole test set is 37 %\n",
      "[413,     8] loss: 0.002\n",
      "For epoch 413 the test accuracy over the whole test set is 37 %\n",
      "[414,     8] loss: 0.002\n",
      "For epoch 414 the test accuracy over the whole test set is 37 %\n",
      "[415,     8] loss: 0.002\n",
      "For epoch 415 the test accuracy over the whole test set is 37 %\n",
      "[416,     8] loss: 0.002\n",
      "For epoch 416 the test accuracy over the whole test set is 37 %\n",
      "[417,     8] loss: 0.002\n",
      "For epoch 417 the test accuracy over the whole test set is 37 %\n",
      "[418,     8] loss: 0.002\n",
      "For epoch 418 the test accuracy over the whole test set is 37 %\n",
      "[419,     8] loss: 0.002\n",
      "For epoch 419 the test accuracy over the whole test set is 37 %\n",
      "[420,     8] loss: 0.002\n",
      "For epoch 420 the test accuracy over the whole test set is 37 %\n",
      "[421,     8] loss: 0.002\n",
      "For epoch 421 the test accuracy over the whole test set is 37 %\n",
      "[422,     8] loss: 0.002\n",
      "For epoch 422 the test accuracy over the whole test set is 37 %\n",
      "[423,     8] loss: 0.002\n",
      "For epoch 423 the test accuracy over the whole test set is 37 %\n",
      "[424,     8] loss: 0.002\n",
      "For epoch 424 the test accuracy over the whole test set is 37 %\n",
      "[425,     8] loss: 0.002\n",
      "For epoch 425 the test accuracy over the whole test set is 37 %\n",
      "[426,     8] loss: 0.002\n",
      "For epoch 426 the test accuracy over the whole test set is 37 %\n",
      "[427,     8] loss: 0.002\n",
      "For epoch 427 the test accuracy over the whole test set is 37 %\n",
      "[428,     8] loss: 0.002\n",
      "For epoch 428 the test accuracy over the whole test set is 37 %\n",
      "[429,     8] loss: 0.002\n",
      "For epoch 429 the test accuracy over the whole test set is 37 %\n",
      "[430,     8] loss: 0.002\n",
      "For epoch 430 the test accuracy over the whole test set is 37 %\n",
      "[431,     8] loss: 0.002\n",
      "For epoch 431 the test accuracy over the whole test set is 37 %\n",
      "[432,     8] loss: 0.002\n",
      "For epoch 432 the test accuracy over the whole test set is 37 %\n",
      "[433,     8] loss: 0.002\n",
      "For epoch 433 the test accuracy over the whole test set is 37 %\n",
      "[434,     8] loss: 0.002\n",
      "For epoch 434 the test accuracy over the whole test set is 37 %\n",
      "[435,     8] loss: 0.002\n",
      "For epoch 435 the test accuracy over the whole test set is 37 %\n",
      "[436,     8] loss: 0.002\n",
      "For epoch 436 the test accuracy over the whole test set is 37 %\n",
      "[437,     8] loss: 0.002\n",
      "For epoch 437 the test accuracy over the whole test set is 37 %\n",
      "[438,     8] loss: 0.002\n",
      "For epoch 438 the test accuracy over the whole test set is 37 %\n",
      "[439,     8] loss: 0.002\n",
      "For epoch 439 the test accuracy over the whole test set is 37 %\n",
      "[440,     8] loss: 0.002\n",
      "For epoch 440 the test accuracy over the whole test set is 37 %\n",
      "[441,     8] loss: 0.002\n",
      "For epoch 441 the test accuracy over the whole test set is 37 %\n",
      "[442,     8] loss: 0.002\n",
      "For epoch 442 the test accuracy over the whole test set is 37 %\n",
      "[443,     8] loss: 0.002\n",
      "For epoch 443 the test accuracy over the whole test set is 37 %\n",
      "[444,     8] loss: 0.002\n",
      "For epoch 444 the test accuracy over the whole test set is 37 %\n",
      "[445,     8] loss: 0.002\n",
      "For epoch 445 the test accuracy over the whole test set is 37 %\n",
      "[446,     8] loss: 0.002\n",
      "For epoch 446 the test accuracy over the whole test set is 37 %\n",
      "[447,     8] loss: 0.002\n",
      "For epoch 447 the test accuracy over the whole test set is 37 %\n",
      "[448,     8] loss: 0.002\n",
      "For epoch 448 the test accuracy over the whole test set is 37 %\n",
      "[449,     8] loss: 0.002\n",
      "For epoch 449 the test accuracy over the whole test set is 37 %\n",
      "[450,     8] loss: 0.002\n",
      "For epoch 450 the test accuracy over the whole test set is 37 %\n",
      "[451,     8] loss: 0.002\n",
      "For epoch 451 the test accuracy over the whole test set is 37 %\n",
      "[452,     8] loss: 0.002\n",
      "For epoch 452 the test accuracy over the whole test set is 37 %\n",
      "[453,     8] loss: 0.002\n",
      "For epoch 453 the test accuracy over the whole test set is 37 %\n",
      "[454,     8] loss: 0.002\n",
      "For epoch 454 the test accuracy over the whole test set is 37 %\n",
      "[455,     8] loss: 0.002\n",
      "For epoch 455 the test accuracy over the whole test set is 37 %\n",
      "[456,     8] loss: 0.002\n",
      "For epoch 456 the test accuracy over the whole test set is 37 %\n",
      "[457,     8] loss: 0.002\n",
      "For epoch 457 the test accuracy over the whole test set is 37 %\n",
      "[458,     8] loss: 0.002\n",
      "For epoch 458 the test accuracy over the whole test set is 37 %\n",
      "[459,     8] loss: 0.002\n",
      "For epoch 459 the test accuracy over the whole test set is 37 %\n",
      "[460,     8] loss: 0.002\n",
      "For epoch 460 the test accuracy over the whole test set is 37 %\n",
      "[461,     8] loss: 0.002\n",
      "For epoch 461 the test accuracy over the whole test set is 37 %\n",
      "[462,     8] loss: 0.002\n",
      "For epoch 462 the test accuracy over the whole test set is 37 %\n",
      "[463,     8] loss: 0.002\n",
      "For epoch 463 the test accuracy over the whole test set is 37 %\n",
      "[464,     8] loss: 0.002\n",
      "For epoch 464 the test accuracy over the whole test set is 37 %\n",
      "[465,     8] loss: 0.002\n",
      "For epoch 465 the test accuracy over the whole test set is 37 %\n",
      "[466,     8] loss: 0.002\n",
      "For epoch 466 the test accuracy over the whole test set is 37 %\n",
      "[467,     8] loss: 0.002\n",
      "For epoch 467 the test accuracy over the whole test set is 37 %\n",
      "[468,     8] loss: 0.002\n",
      "For epoch 468 the test accuracy over the whole test set is 37 %\n",
      "[469,     8] loss: 0.002\n",
      "For epoch 469 the test accuracy over the whole test set is 37 %\n",
      "[470,     8] loss: 0.002\n",
      "For epoch 470 the test accuracy over the whole test set is 37 %\n",
      "[471,     8] loss: 0.002\n",
      "For epoch 471 the test accuracy over the whole test set is 37 %\n",
      "[472,     8] loss: 0.002\n",
      "For epoch 472 the test accuracy over the whole test set is 37 %\n",
      "[473,     8] loss: 0.002\n",
      "For epoch 473 the test accuracy over the whole test set is 37 %\n",
      "[474,     8] loss: 0.002\n",
      "For epoch 474 the test accuracy over the whole test set is 37 %\n",
      "[475,     8] loss: 0.002\n",
      "For epoch 475 the test accuracy over the whole test set is 37 %\n",
      "[476,     8] loss: 0.002\n",
      "For epoch 476 the test accuracy over the whole test set is 37 %\n",
      "[477,     8] loss: 0.002\n",
      "For epoch 477 the test accuracy over the whole test set is 37 %\n",
      "[478,     8] loss: 0.002\n",
      "For epoch 478 the test accuracy over the whole test set is 37 %\n",
      "[479,     8] loss: 0.002\n",
      "For epoch 479 the test accuracy over the whole test set is 37 %\n",
      "[480,     8] loss: 0.002\n",
      "For epoch 480 the test accuracy over the whole test set is 37 %\n",
      "[481,     8] loss: 0.002\n",
      "For epoch 481 the test accuracy over the whole test set is 37 %\n",
      "[482,     8] loss: 0.002\n",
      "For epoch 482 the test accuracy over the whole test set is 37 %\n",
      "[483,     8] loss: 0.002\n",
      "For epoch 483 the test accuracy over the whole test set is 37 %\n",
      "[484,     8] loss: 0.002\n",
      "For epoch 484 the test accuracy over the whole test set is 37 %\n",
      "[485,     8] loss: 0.002\n",
      "For epoch 485 the test accuracy over the whole test set is 37 %\n",
      "[486,     8] loss: 0.002\n",
      "For epoch 486 the test accuracy over the whole test set is 37 %\n",
      "[487,     8] loss: 0.002\n",
      "For epoch 487 the test accuracy over the whole test set is 37 %\n",
      "[488,     8] loss: 0.002\n",
      "For epoch 488 the test accuracy over the whole test set is 37 %\n",
      "[489,     8] loss: 0.002\n",
      "For epoch 489 the test accuracy over the whole test set is 37 %\n",
      "[490,     8] loss: 0.002\n",
      "For epoch 490 the test accuracy over the whole test set is 37 %\n",
      "[491,     8] loss: 0.002\n",
      "For epoch 491 the test accuracy over the whole test set is 37 %\n",
      "[492,     8] loss: 0.002\n",
      "For epoch 492 the test accuracy over the whole test set is 37 %\n",
      "[493,     8] loss: 0.002\n",
      "For epoch 493 the test accuracy over the whole test set is 37 %\n",
      "[494,     8] loss: 0.002\n",
      "For epoch 494 the test accuracy over the whole test set is 37 %\n",
      "[495,     8] loss: 0.002\n",
      "For epoch 495 the test accuracy over the whole test set is 37 %\n",
      "[496,     8] loss: 0.002\n",
      "For epoch 496 the test accuracy over the whole test set is 37 %\n",
      "[497,     8] loss: 0.002\n",
      "For epoch 497 the test accuracy over the whole test set is 37 %\n",
      "[498,     8] loss: 0.002\n",
      "For epoch 498 the test accuracy over the whole test set is 37 %\n",
      "[499,     8] loss: 0.002\n",
      "For epoch 499 the test accuracy over the whole test set is 37 %\n",
      "[500,     8] loss: 0.002\n",
      "For epoch 500 the test accuracy over the whole test set is 37 %\n",
      "[501,     8] loss: 0.002\n",
      "For epoch 501 the test accuracy over the whole test set is 37 %\n",
      "[502,     8] loss: 0.002\n",
      "For epoch 502 the test accuracy over the whole test set is 37 %\n",
      "[503,     8] loss: 0.002\n",
      "For epoch 503 the test accuracy over the whole test set is 37 %\n",
      "[504,     8] loss: 0.002\n",
      "For epoch 504 the test accuracy over the whole test set is 37 %\n",
      "[505,     8] loss: 0.002\n",
      "For epoch 505 the test accuracy over the whole test set is 37 %\n",
      "[506,     8] loss: 0.002\n",
      "For epoch 506 the test accuracy over the whole test set is 37 %\n",
      "[507,     8] loss: 0.002\n",
      "For epoch 507 the test accuracy over the whole test set is 37 %\n",
      "[508,     8] loss: 0.002\n",
      "For epoch 508 the test accuracy over the whole test set is 37 %\n",
      "[509,     8] loss: 0.002\n",
      "For epoch 509 the test accuracy over the whole test set is 37 %\n",
      "[510,     8] loss: 0.002\n",
      "For epoch 510 the test accuracy over the whole test set is 37 %\n",
      "[511,     8] loss: 0.002\n",
      "For epoch 511 the test accuracy over the whole test set is 37 %\n",
      "[512,     8] loss: 0.002\n",
      "For epoch 512 the test accuracy over the whole test set is 37 %\n",
      "[513,     8] loss: 0.002\n",
      "For epoch 513 the test accuracy over the whole test set is 37 %\n",
      "[514,     8] loss: 0.002\n",
      "For epoch 514 the test accuracy over the whole test set is 37 %\n",
      "[515,     8] loss: 0.002\n",
      "For epoch 515 the test accuracy over the whole test set is 37 %\n",
      "[516,     8] loss: 0.002\n",
      "For epoch 516 the test accuracy over the whole test set is 37 %\n",
      "[517,     8] loss: 0.002\n",
      "For epoch 517 the test accuracy over the whole test set is 37 %\n",
      "[518,     8] loss: 0.002\n",
      "For epoch 518 the test accuracy over the whole test set is 37 %\n",
      "[519,     8] loss: 0.002\n",
      "For epoch 519 the test accuracy over the whole test set is 37 %\n",
      "[520,     8] loss: 0.002\n",
      "For epoch 520 the test accuracy over the whole test set is 37 %\n",
      "[521,     8] loss: 0.002\n",
      "For epoch 521 the test accuracy over the whole test set is 37 %\n",
      "[522,     8] loss: 0.002\n",
      "For epoch 522 the test accuracy over the whole test set is 37 %\n",
      "[523,     8] loss: 0.002\n",
      "For epoch 523 the test accuracy over the whole test set is 37 %\n",
      "[524,     8] loss: 0.002\n",
      "For epoch 524 the test accuracy over the whole test set is 37 %\n",
      "[525,     8] loss: 0.002\n",
      "For epoch 525 the test accuracy over the whole test set is 37 %\n",
      "[526,     8] loss: 0.002\n",
      "For epoch 526 the test accuracy over the whole test set is 37 %\n",
      "[527,     8] loss: 0.002\n",
      "For epoch 527 the test accuracy over the whole test set is 37 %\n",
      "[528,     8] loss: 0.002\n",
      "For epoch 528 the test accuracy over the whole test set is 37 %\n",
      "[529,     8] loss: 0.002\n",
      "For epoch 529 the test accuracy over the whole test set is 37 %\n",
      "[530,     8] loss: 0.002\n",
      "For epoch 530 the test accuracy over the whole test set is 37 %\n",
      "[531,     8] loss: 0.002\n",
      "For epoch 531 the test accuracy over the whole test set is 37 %\n",
      "[532,     8] loss: 0.002\n",
      "For epoch 532 the test accuracy over the whole test set is 37 %\n",
      "[533,     8] loss: 0.002\n",
      "For epoch 533 the test accuracy over the whole test set is 37 %\n",
      "[534,     8] loss: 0.002\n",
      "For epoch 534 the test accuracy over the whole test set is 37 %\n",
      "[535,     8] loss: 0.002\n",
      "For epoch 535 the test accuracy over the whole test set is 37 %\n",
      "[536,     8] loss: 0.002\n",
      "For epoch 536 the test accuracy over the whole test set is 37 %\n",
      "[537,     8] loss: 0.002\n",
      "For epoch 537 the test accuracy over the whole test set is 37 %\n",
      "[538,     8] loss: 0.002\n",
      "For epoch 538 the test accuracy over the whole test set is 37 %\n",
      "[539,     8] loss: 0.002\n",
      "For epoch 539 the test accuracy over the whole test set is 37 %\n",
      "[540,     8] loss: 0.002\n",
      "For epoch 540 the test accuracy over the whole test set is 37 %\n",
      "[541,     8] loss: 0.002\n",
      "For epoch 541 the test accuracy over the whole test set is 37 %\n",
      "[542,     8] loss: 0.002\n",
      "For epoch 542 the test accuracy over the whole test set is 37 %\n",
      "[543,     8] loss: 0.002\n",
      "For epoch 543 the test accuracy over the whole test set is 37 %\n",
      "[544,     8] loss: 0.002\n",
      "For epoch 544 the test accuracy over the whole test set is 37 %\n",
      "[545,     8] loss: 0.002\n",
      "For epoch 545 the test accuracy over the whole test set is 37 %\n",
      "[546,     8] loss: 0.002\n",
      "For epoch 546 the test accuracy over the whole test set is 37 %\n",
      "[547,     8] loss: 0.002\n",
      "For epoch 547 the test accuracy over the whole test set is 37 %\n",
      "[548,     8] loss: 0.002\n",
      "For epoch 548 the test accuracy over the whole test set is 37 %\n",
      "[549,     8] loss: 0.002\n",
      "For epoch 549 the test accuracy over the whole test set is 37 %\n",
      "[550,     8] loss: 0.002\n",
      "For epoch 550 the test accuracy over the whole test set is 37 %\n",
      "[551,     8] loss: 0.002\n",
      "For epoch 551 the test accuracy over the whole test set is 37 %\n",
      "[552,     8] loss: 0.002\n",
      "For epoch 552 the test accuracy over the whole test set is 37 %\n",
      "[553,     8] loss: 0.002\n",
      "For epoch 553 the test accuracy over the whole test set is 37 %\n",
      "[554,     8] loss: 0.002\n",
      "For epoch 554 the test accuracy over the whole test set is 37 %\n",
      "[555,     8] loss: 0.002\n",
      "For epoch 555 the test accuracy over the whole test set is 37 %\n",
      "[556,     8] loss: 0.002\n",
      "For epoch 556 the test accuracy over the whole test set is 37 %\n",
      "[557,     8] loss: 0.002\n",
      "For epoch 557 the test accuracy over the whole test set is 37 %\n",
      "[558,     8] loss: 0.002\n",
      "For epoch 558 the test accuracy over the whole test set is 37 %\n",
      "[559,     8] loss: 0.002\n",
      "For epoch 559 the test accuracy over the whole test set is 37 %\n",
      "[560,     8] loss: 0.002\n",
      "For epoch 560 the test accuracy over the whole test set is 37 %\n",
      "[561,     8] loss: 0.002\n",
      "For epoch 561 the test accuracy over the whole test set is 37 %\n",
      "[562,     8] loss: 0.002\n",
      "For epoch 562 the test accuracy over the whole test set is 37 %\n",
      "[563,     8] loss: 0.002\n",
      "For epoch 563 the test accuracy over the whole test set is 37 %\n",
      "[564,     8] loss: 0.002\n",
      "For epoch 564 the test accuracy over the whole test set is 37 %\n",
      "[565,     8] loss: 0.002\n",
      "For epoch 565 the test accuracy over the whole test set is 37 %\n",
      "[566,     8] loss: 0.002\n",
      "For epoch 566 the test accuracy over the whole test set is 37 %\n",
      "[567,     8] loss: 0.002\n",
      "For epoch 567 the test accuracy over the whole test set is 37 %\n",
      "[568,     8] loss: 0.002\n",
      "For epoch 568 the test accuracy over the whole test set is 37 %\n",
      "[569,     8] loss: 0.002\n",
      "For epoch 569 the test accuracy over the whole test set is 37 %\n",
      "[570,     8] loss: 0.002\n",
      "For epoch 570 the test accuracy over the whole test set is 37 %\n",
      "[571,     8] loss: 0.002\n",
      "For epoch 571 the test accuracy over the whole test set is 37 %\n",
      "[572,     8] loss: 0.002\n",
      "For epoch 572 the test accuracy over the whole test set is 37 %\n",
      "[573,     8] loss: 0.002\n",
      "For epoch 573 the test accuracy over the whole test set is 37 %\n",
      "[574,     8] loss: 0.002\n",
      "For epoch 574 the test accuracy over the whole test set is 37 %\n",
      "[575,     8] loss: 0.002\n",
      "For epoch 575 the test accuracy over the whole test set is 37 %\n",
      "[576,     8] loss: 0.002\n",
      "For epoch 576 the test accuracy over the whole test set is 37 %\n",
      "[577,     8] loss: 0.002\n",
      "For epoch 577 the test accuracy over the whole test set is 37 %\n",
      "[578,     8] loss: 0.002\n",
      "For epoch 578 the test accuracy over the whole test set is 37 %\n",
      "[579,     8] loss: 0.002\n",
      "For epoch 579 the test accuracy over the whole test set is 37 %\n",
      "[580,     8] loss: 0.002\n",
      "For epoch 580 the test accuracy over the whole test set is 37 %\n",
      "[581,     8] loss: 0.002\n",
      "For epoch 581 the test accuracy over the whole test set is 37 %\n",
      "[582,     8] loss: 0.002\n",
      "For epoch 582 the test accuracy over the whole test set is 37 %\n",
      "[583,     8] loss: 0.002\n",
      "For epoch 583 the test accuracy over the whole test set is 37 %\n",
      "[584,     8] loss: 0.002\n",
      "For epoch 584 the test accuracy over the whole test set is 37 %\n",
      "[585,     8] loss: 0.002\n",
      "For epoch 585 the test accuracy over the whole test set is 37 %\n",
      "[586,     8] loss: 0.002\n",
      "For epoch 586 the test accuracy over the whole test set is 37 %\n",
      "[587,     8] loss: 0.002\n",
      "For epoch 587 the test accuracy over the whole test set is 37 %\n",
      "[588,     8] loss: 0.002\n",
      "For epoch 588 the test accuracy over the whole test set is 37 %\n",
      "[589,     8] loss: 0.002\n",
      "For epoch 589 the test accuracy over the whole test set is 37 %\n",
      "[590,     8] loss: 0.002\n",
      "For epoch 590 the test accuracy over the whole test set is 37 %\n",
      "[591,     8] loss: 0.002\n",
      "For epoch 591 the test accuracy over the whole test set is 37 %\n",
      "[592,     8] loss: 0.002\n",
      "For epoch 592 the test accuracy over the whole test set is 37 %\n",
      "[593,     8] loss: 0.002\n",
      "For epoch 593 the test accuracy over the whole test set is 37 %\n",
      "[594,     8] loss: 0.002\n",
      "For epoch 594 the test accuracy over the whole test set is 37 %\n",
      "[595,     8] loss: 0.002\n",
      "For epoch 595 the test accuracy over the whole test set is 37 %\n",
      "[596,     8] loss: 0.002\n",
      "For epoch 596 the test accuracy over the whole test set is 37 %\n",
      "[597,     8] loss: 0.002\n",
      "For epoch 597 the test accuracy over the whole test set is 37 %\n",
      "[598,     8] loss: 0.002\n",
      "For epoch 598 the test accuracy over the whole test set is 37 %\n",
      "[599,     8] loss: 0.002\n",
      "For epoch 599 the test accuracy over the whole test set is 37 %\n",
      "[600,     8] loss: 0.002\n",
      "For epoch 600 the test accuracy over the whole test set is 37 %\n",
      "[601,     8] loss: 0.002\n",
      "For epoch 601 the test accuracy over the whole test set is 37 %\n",
      "[602,     8] loss: 0.002\n",
      "For epoch 602 the test accuracy over the whole test set is 37 %\n",
      "[603,     8] loss: 0.002\n",
      "For epoch 603 the test accuracy over the whole test set is 37 %\n",
      "[604,     8] loss: 0.002\n",
      "For epoch 604 the test accuracy over the whole test set is 37 %\n",
      "[605,     8] loss: 0.002\n",
      "For epoch 605 the test accuracy over the whole test set is 37 %\n",
      "[606,     8] loss: 0.002\n",
      "For epoch 606 the test accuracy over the whole test set is 37 %\n",
      "[607,     8] loss: 0.002\n",
      "For epoch 607 the test accuracy over the whole test set is 37 %\n",
      "[608,     8] loss: 0.002\n",
      "For epoch 608 the test accuracy over the whole test set is 37 %\n",
      "[609,     8] loss: 0.002\n",
      "For epoch 609 the test accuracy over the whole test set is 37 %\n",
      "[610,     8] loss: 0.002\n",
      "For epoch 610 the test accuracy over the whole test set is 37 %\n",
      "[611,     8] loss: 0.002\n",
      "For epoch 611 the test accuracy over the whole test set is 37 %\n",
      "[612,     8] loss: 0.002\n",
      "For epoch 612 the test accuracy over the whole test set is 37 %\n",
      "[613,     8] loss: 0.002\n",
      "For epoch 613 the test accuracy over the whole test set is 37 %\n",
      "[614,     8] loss: 0.002\n",
      "For epoch 614 the test accuracy over the whole test set is 37 %\n",
      "[615,     8] loss: 0.002\n",
      "For epoch 615 the test accuracy over the whole test set is 37 %\n",
      "[616,     8] loss: 0.002\n",
      "For epoch 616 the test accuracy over the whole test set is 37 %\n",
      "[617,     8] loss: 0.002\n",
      "For epoch 617 the test accuracy over the whole test set is 37 %\n",
      "[618,     8] loss: 0.002\n",
      "For epoch 618 the test accuracy over the whole test set is 37 %\n",
      "[619,     8] loss: 0.002\n",
      "For epoch 619 the test accuracy over the whole test set is 37 %\n",
      "[620,     8] loss: 0.002\n",
      "For epoch 620 the test accuracy over the whole test set is 37 %\n",
      "[621,     8] loss: 0.002\n",
      "For epoch 621 the test accuracy over the whole test set is 37 %\n",
      "[622,     8] loss: 0.002\n",
      "For epoch 622 the test accuracy over the whole test set is 37 %\n",
      "[623,     8] loss: 0.002\n",
      "For epoch 623 the test accuracy over the whole test set is 37 %\n",
      "[624,     8] loss: 0.002\n",
      "For epoch 624 the test accuracy over the whole test set is 37 %\n",
      "[625,     8] loss: 0.002\n",
      "For epoch 625 the test accuracy over the whole test set is 37 %\n",
      "[626,     8] loss: 0.002\n",
      "For epoch 626 the test accuracy over the whole test set is 37 %\n",
      "[627,     8] loss: 0.002\n",
      "For epoch 627 the test accuracy over the whole test set is 37 %\n",
      "[628,     8] loss: 0.002\n",
      "For epoch 628 the test accuracy over the whole test set is 37 %\n",
      "[629,     8] loss: 0.002\n",
      "For epoch 629 the test accuracy over the whole test set is 37 %\n",
      "[630,     8] loss: 0.002\n",
      "For epoch 630 the test accuracy over the whole test set is 37 %\n",
      "[631,     8] loss: 0.002\n",
      "For epoch 631 the test accuracy over the whole test set is 37 %\n",
      "[632,     8] loss: 0.002\n",
      "For epoch 632 the test accuracy over the whole test set is 37 %\n",
      "[633,     8] loss: 0.002\n",
      "For epoch 633 the test accuracy over the whole test set is 37 %\n",
      "[634,     8] loss: 0.002\n",
      "For epoch 634 the test accuracy over the whole test set is 37 %\n",
      "[635,     8] loss: 0.002\n",
      "For epoch 635 the test accuracy over the whole test set is 37 %\n",
      "[636,     8] loss: 0.002\n",
      "For epoch 636 the test accuracy over the whole test set is 37 %\n",
      "[637,     8] loss: 0.002\n",
      "For epoch 637 the test accuracy over the whole test set is 37 %\n",
      "[638,     8] loss: 0.002\n",
      "For epoch 638 the test accuracy over the whole test set is 37 %\n",
      "[639,     8] loss: 0.002\n",
      "For epoch 639 the test accuracy over the whole test set is 37 %\n",
      "[640,     8] loss: 0.002\n",
      "For epoch 640 the test accuracy over the whole test set is 37 %\n",
      "[641,     8] loss: 0.002\n",
      "For epoch 641 the test accuracy over the whole test set is 37 %\n",
      "[642,     8] loss: 0.002\n",
      "For epoch 642 the test accuracy over the whole test set is 37 %\n",
      "[643,     8] loss: 0.002\n",
      "For epoch 643 the test accuracy over the whole test set is 37 %\n",
      "[644,     8] loss: 0.002\n",
      "For epoch 644 the test accuracy over the whole test set is 37 %\n",
      "[645,     8] loss: 0.002\n",
      "For epoch 645 the test accuracy over the whole test set is 37 %\n",
      "[646,     8] loss: 0.002\n",
      "For epoch 646 the test accuracy over the whole test set is 37 %\n",
      "[647,     8] loss: 0.002\n",
      "For epoch 647 the test accuracy over the whole test set is 37 %\n",
      "[648,     8] loss: 0.002\n",
      "For epoch 648 the test accuracy over the whole test set is 37 %\n",
      "[649,     8] loss: 0.002\n",
      "For epoch 649 the test accuracy over the whole test set is 37 %\n",
      "[650,     8] loss: 0.002\n",
      "For epoch 650 the test accuracy over the whole test set is 37 %\n",
      "[651,     8] loss: 0.002\n",
      "For epoch 651 the test accuracy over the whole test set is 37 %\n",
      "[652,     8] loss: 0.002\n",
      "For epoch 652 the test accuracy over the whole test set is 37 %\n",
      "[653,     8] loss: 0.002\n",
      "For epoch 653 the test accuracy over the whole test set is 37 %\n",
      "[654,     8] loss: 0.002\n",
      "For epoch 654 the test accuracy over the whole test set is 37 %\n",
      "[655,     8] loss: 0.002\n",
      "For epoch 655 the test accuracy over the whole test set is 37 %\n",
      "[656,     8] loss: 0.002\n",
      "For epoch 656 the test accuracy over the whole test set is 37 %\n",
      "[657,     8] loss: 0.002\n",
      "For epoch 657 the test accuracy over the whole test set is 37 %\n",
      "[658,     8] loss: 0.002\n",
      "For epoch 658 the test accuracy over the whole test set is 37 %\n",
      "[659,     8] loss: 0.002\n",
      "For epoch 659 the test accuracy over the whole test set is 37 %\n",
      "[660,     8] loss: 0.002\n",
      "For epoch 660 the test accuracy over the whole test set is 37 %\n",
      "[661,     8] loss: 0.002\n",
      "For epoch 661 the test accuracy over the whole test set is 37 %\n",
      "[662,     8] loss: 0.002\n",
      "For epoch 662 the test accuracy over the whole test set is 37 %\n",
      "[663,     8] loss: 0.002\n",
      "For epoch 663 the test accuracy over the whole test set is 37 %\n",
      "[664,     8] loss: 0.002\n",
      "For epoch 664 the test accuracy over the whole test set is 37 %\n",
      "[665,     8] loss: 0.002\n",
      "For epoch 665 the test accuracy over the whole test set is 37 %\n",
      "[666,     8] loss: 0.002\n",
      "For epoch 666 the test accuracy over the whole test set is 37 %\n",
      "[667,     8] loss: 0.002\n",
      "For epoch 667 the test accuracy over the whole test set is 37 %\n",
      "[668,     8] loss: 0.002\n",
      "For epoch 668 the test accuracy over the whole test set is 37 %\n",
      "[669,     8] loss: 0.002\n",
      "For epoch 669 the test accuracy over the whole test set is 37 %\n",
      "[670,     8] loss: 0.002\n",
      "For epoch 670 the test accuracy over the whole test set is 37 %\n",
      "[671,     8] loss: 0.002\n",
      "For epoch 671 the test accuracy over the whole test set is 37 %\n",
      "[672,     8] loss: 0.002\n",
      "For epoch 672 the test accuracy over the whole test set is 37 %\n",
      "[673,     8] loss: 0.002\n",
      "For epoch 673 the test accuracy over the whole test set is 37 %\n",
      "[674,     8] loss: 0.002\n",
      "For epoch 674 the test accuracy over the whole test set is 37 %\n",
      "[675,     8] loss: 0.002\n",
      "For epoch 675 the test accuracy over the whole test set is 37 %\n",
      "[676,     8] loss: 0.002\n",
      "For epoch 676 the test accuracy over the whole test set is 37 %\n",
      "[677,     8] loss: 0.002\n",
      "For epoch 677 the test accuracy over the whole test set is 37 %\n",
      "[678,     8] loss: 0.002\n",
      "For epoch 678 the test accuracy over the whole test set is 37 %\n",
      "[679,     8] loss: 0.002\n",
      "For epoch 679 the test accuracy over the whole test set is 37 %\n",
      "[680,     8] loss: 0.002\n",
      "For epoch 680 the test accuracy over the whole test set is 37 %\n",
      "[681,     8] loss: 0.002\n",
      "For epoch 681 the test accuracy over the whole test set is 37 %\n",
      "[682,     8] loss: 0.002\n",
      "For epoch 682 the test accuracy over the whole test set is 37 %\n",
      "[683,     8] loss: 0.002\n",
      "For epoch 683 the test accuracy over the whole test set is 37 %\n",
      "[684,     8] loss: 0.002\n",
      "For epoch 684 the test accuracy over the whole test set is 37 %\n",
      "[685,     8] loss: 0.002\n",
      "For epoch 685 the test accuracy over the whole test set is 37 %\n",
      "[686,     8] loss: 0.002\n",
      "For epoch 686 the test accuracy over the whole test set is 37 %\n",
      "[687,     8] loss: 0.002\n",
      "For epoch 687 the test accuracy over the whole test set is 37 %\n",
      "[688,     8] loss: 0.002\n",
      "For epoch 688 the test accuracy over the whole test set is 37 %\n",
      "[689,     8] loss: 0.002\n",
      "For epoch 689 the test accuracy over the whole test set is 37 %\n",
      "[690,     8] loss: 0.002\n",
      "For epoch 690 the test accuracy over the whole test set is 37 %\n",
      "[691,     8] loss: 0.002\n",
      "For epoch 691 the test accuracy over the whole test set is 37 %\n",
      "[692,     8] loss: 0.002\n",
      "For epoch 692 the test accuracy over the whole test set is 37 %\n",
      "[693,     8] loss: 0.002\n",
      "For epoch 693 the test accuracy over the whole test set is 37 %\n",
      "[694,     8] loss: 0.002\n",
      "For epoch 694 the test accuracy over the whole test set is 37 %\n",
      "[695,     8] loss: 0.002\n",
      "For epoch 695 the test accuracy over the whole test set is 37 %\n",
      "[696,     8] loss: 0.002\n",
      "For epoch 696 the test accuracy over the whole test set is 37 %\n",
      "[697,     8] loss: 0.002\n",
      "For epoch 697 the test accuracy over the whole test set is 37 %\n",
      "[698,     8] loss: 0.002\n",
      "For epoch 698 the test accuracy over the whole test set is 37 %\n",
      "[699,     8] loss: 0.002\n",
      "For epoch 699 the test accuracy over the whole test set is 37 %\n",
      "[700,     8] loss: 0.002\n",
      "For epoch 700 the test accuracy over the whole test set is 37 %\n",
      "[701,     8] loss: 0.002\n",
      "For epoch 701 the test accuracy over the whole test set is 37 %\n",
      "[702,     8] loss: 0.002\n",
      "For epoch 702 the test accuracy over the whole test set is 37 %\n",
      "[703,     8] loss: 0.002\n",
      "For epoch 703 the test accuracy over the whole test set is 37 %\n",
      "[704,     8] loss: 0.002\n",
      "For epoch 704 the test accuracy over the whole test set is 37 %\n",
      "[705,     8] loss: 0.002\n",
      "For epoch 705 the test accuracy over the whole test set is 37 %\n",
      "[706,     8] loss: 0.002\n",
      "For epoch 706 the test accuracy over the whole test set is 37 %\n",
      "[707,     8] loss: 0.002\n",
      "For epoch 707 the test accuracy over the whole test set is 37 %\n",
      "[708,     8] loss: 0.002\n",
      "For epoch 708 the test accuracy over the whole test set is 37 %\n",
      "[709,     8] loss: 0.002\n",
      "For epoch 709 the test accuracy over the whole test set is 37 %\n",
      "[710,     8] loss: 0.002\n",
      "For epoch 710 the test accuracy over the whole test set is 37 %\n",
      "[711,     8] loss: 0.002\n",
      "For epoch 711 the test accuracy over the whole test set is 37 %\n",
      "[712,     8] loss: 0.002\n",
      "For epoch 712 the test accuracy over the whole test set is 37 %\n",
      "[713,     8] loss: 0.002\n",
      "For epoch 713 the test accuracy over the whole test set is 37 %\n",
      "[714,     8] loss: 0.002\n",
      "For epoch 714 the test accuracy over the whole test set is 37 %\n",
      "[715,     8] loss: 0.002\n",
      "For epoch 715 the test accuracy over the whole test set is 37 %\n",
      "[716,     8] loss: 0.002\n",
      "For epoch 716 the test accuracy over the whole test set is 37 %\n",
      "[717,     8] loss: 0.002\n",
      "For epoch 717 the test accuracy over the whole test set is 37 %\n",
      "[718,     8] loss: 0.002\n",
      "For epoch 718 the test accuracy over the whole test set is 37 %\n",
      "[719,     8] loss: 0.002\n",
      "For epoch 719 the test accuracy over the whole test set is 37 %\n",
      "[720,     8] loss: 0.002\n",
      "For epoch 720 the test accuracy over the whole test set is 37 %\n",
      "[721,     8] loss: 0.002\n",
      "For epoch 721 the test accuracy over the whole test set is 37 %\n",
      "[722,     8] loss: 0.002\n",
      "For epoch 722 the test accuracy over the whole test set is 37 %\n",
      "[723,     8] loss: 0.002\n",
      "For epoch 723 the test accuracy over the whole test set is 37 %\n",
      "[724,     8] loss: 0.002\n",
      "For epoch 724 the test accuracy over the whole test set is 37 %\n",
      "[725,     8] loss: 0.002\n",
      "For epoch 725 the test accuracy over the whole test set is 37 %\n",
      "[726,     8] loss: 0.002\n",
      "For epoch 726 the test accuracy over the whole test set is 37 %\n",
      "[727,     8] loss: 0.002\n",
      "For epoch 727 the test accuracy over the whole test set is 37 %\n",
      "[728,     8] loss: 0.002\n",
      "For epoch 728 the test accuracy over the whole test set is 37 %\n",
      "[729,     8] loss: 0.002\n",
      "For epoch 729 the test accuracy over the whole test set is 37 %\n",
      "[730,     8] loss: 0.002\n",
      "For epoch 730 the test accuracy over the whole test set is 37 %\n",
      "[731,     8] loss: 0.002\n",
      "For epoch 731 the test accuracy over the whole test set is 37 %\n",
      "[732,     8] loss: 0.002\n",
      "For epoch 732 the test accuracy over the whole test set is 37 %\n",
      "[733,     8] loss: 0.002\n",
      "For epoch 733 the test accuracy over the whole test set is 37 %\n",
      "[734,     8] loss: 0.002\n",
      "For epoch 734 the test accuracy over the whole test set is 37 %\n",
      "[735,     8] loss: 0.002\n",
      "For epoch 735 the test accuracy over the whole test set is 37 %\n",
      "[736,     8] loss: 0.002\n",
      "For epoch 736 the test accuracy over the whole test set is 37 %\n",
      "[737,     8] loss: 0.002\n",
      "For epoch 737 the test accuracy over the whole test set is 37 %\n",
      "[738,     8] loss: 0.002\n",
      "For epoch 738 the test accuracy over the whole test set is 37 %\n",
      "[739,     8] loss: 0.002\n",
      "For epoch 739 the test accuracy over the whole test set is 37 %\n",
      "[740,     8] loss: 0.002\n",
      "For epoch 740 the test accuracy over the whole test set is 37 %\n",
      "[741,     8] loss: 0.002\n",
      "For epoch 741 the test accuracy over the whole test set is 37 %\n",
      "[742,     8] loss: 0.002\n",
      "For epoch 742 the test accuracy over the whole test set is 37 %\n",
      "[743,     8] loss: 0.002\n",
      "For epoch 743 the test accuracy over the whole test set is 37 %\n",
      "[744,     8] loss: 0.002\n",
      "For epoch 744 the test accuracy over the whole test set is 37 %\n",
      "[745,     8] loss: 0.002\n",
      "For epoch 745 the test accuracy over the whole test set is 37 %\n",
      "[746,     8] loss: 0.002\n",
      "For epoch 746 the test accuracy over the whole test set is 37 %\n",
      "[747,     8] loss: 0.002\n",
      "For epoch 747 the test accuracy over the whole test set is 37 %\n",
      "[748,     8] loss: 0.002\n",
      "For epoch 748 the test accuracy over the whole test set is 37 %\n",
      "[749,     8] loss: 0.002\n",
      "For epoch 749 the test accuracy over the whole test set is 37 %\n",
      "[750,     8] loss: 0.002\n",
      "For epoch 750 the test accuracy over the whole test set is 37 %\n",
      "[751,     8] loss: 0.002\n",
      "For epoch 751 the test accuracy over the whole test set is 37 %\n",
      "[752,     8] loss: 0.002\n",
      "For epoch 752 the test accuracy over the whole test set is 37 %\n",
      "[753,     8] loss: 0.002\n",
      "For epoch 753 the test accuracy over the whole test set is 37 %\n",
      "[754,     8] loss: 0.002\n",
      "For epoch 754 the test accuracy over the whole test set is 37 %\n",
      "[755,     8] loss: 0.002\n",
      "For epoch 755 the test accuracy over the whole test set is 37 %\n",
      "[756,     8] loss: 0.002\n",
      "For epoch 756 the test accuracy over the whole test set is 37 %\n",
      "[757,     8] loss: 0.002\n",
      "For epoch 757 the test accuracy over the whole test set is 37 %\n",
      "[758,     8] loss: 0.002\n",
      "For epoch 758 the test accuracy over the whole test set is 37 %\n",
      "[759,     8] loss: 0.002\n",
      "For epoch 759 the test accuracy over the whole test set is 37 %\n",
      "[760,     8] loss: 0.002\n",
      "For epoch 760 the test accuracy over the whole test set is 37 %\n",
      "[761,     8] loss: 0.002\n",
      "For epoch 761 the test accuracy over the whole test set is 37 %\n",
      "[762,     8] loss: 0.002\n",
      "For epoch 762 the test accuracy over the whole test set is 37 %\n",
      "[763,     8] loss: 0.002\n",
      "For epoch 763 the test accuracy over the whole test set is 37 %\n",
      "[764,     8] loss: 0.002\n",
      "For epoch 764 the test accuracy over the whole test set is 37 %\n",
      "[765,     8] loss: 0.002\n",
      "For epoch 765 the test accuracy over the whole test set is 37 %\n",
      "[766,     8] loss: 0.002\n",
      "For epoch 766 the test accuracy over the whole test set is 37 %\n",
      "[767,     8] loss: 0.002\n",
      "For epoch 767 the test accuracy over the whole test set is 37 %\n",
      "[768,     8] loss: 0.002\n",
      "For epoch 768 the test accuracy over the whole test set is 37 %\n",
      "[769,     8] loss: 0.002\n",
      "For epoch 769 the test accuracy over the whole test set is 37 %\n",
      "[770,     8] loss: 0.002\n",
      "For epoch 770 the test accuracy over the whole test set is 37 %\n",
      "[771,     8] loss: 0.002\n",
      "For epoch 771 the test accuracy over the whole test set is 37 %\n",
      "[772,     8] loss: 0.002\n",
      "For epoch 772 the test accuracy over the whole test set is 37 %\n",
      "[773,     8] loss: 0.002\n",
      "For epoch 773 the test accuracy over the whole test set is 37 %\n",
      "[774,     8] loss: 0.002\n",
      "For epoch 774 the test accuracy over the whole test set is 37 %\n",
      "[775,     8] loss: 0.002\n",
      "For epoch 775 the test accuracy over the whole test set is 37 %\n",
      "[776,     8] loss: 0.002\n",
      "For epoch 776 the test accuracy over the whole test set is 37 %\n",
      "[777,     8] loss: 0.002\n",
      "For epoch 777 the test accuracy over the whole test set is 37 %\n",
      "[778,     8] loss: 0.002\n",
      "For epoch 778 the test accuracy over the whole test set is 37 %\n",
      "[779,     8] loss: 0.002\n",
      "For epoch 779 the test accuracy over the whole test set is 37 %\n",
      "[780,     8] loss: 0.002\n",
      "For epoch 780 the test accuracy over the whole test set is 37 %\n",
      "[781,     8] loss: 0.002\n",
      "For epoch 781 the test accuracy over the whole test set is 37 %\n",
      "[782,     8] loss: 0.002\n",
      "For epoch 782 the test accuracy over the whole test set is 37 %\n",
      "[783,     8] loss: 0.002\n",
      "For epoch 783 the test accuracy over the whole test set is 37 %\n",
      "[784,     8] loss: 0.002\n",
      "For epoch 784 the test accuracy over the whole test set is 37 %\n",
      "[785,     8] loss: 0.002\n",
      "For epoch 785 the test accuracy over the whole test set is 37 %\n",
      "[786,     8] loss: 0.002\n",
      "For epoch 786 the test accuracy over the whole test set is 37 %\n",
      "[787,     8] loss: 0.002\n",
      "For epoch 787 the test accuracy over the whole test set is 37 %\n",
      "[788,     8] loss: 0.002\n",
      "For epoch 788 the test accuracy over the whole test set is 37 %\n",
      "[789,     8] loss: 0.002\n",
      "For epoch 789 the test accuracy over the whole test set is 37 %\n",
      "[790,     8] loss: 0.002\n",
      "For epoch 790 the test accuracy over the whole test set is 37 %\n",
      "[791,     8] loss: 0.002\n",
      "For epoch 791 the test accuracy over the whole test set is 37 %\n",
      "[792,     8] loss: 0.002\n",
      "For epoch 792 the test accuracy over the whole test set is 37 %\n",
      "[793,     8] loss: 0.002\n",
      "For epoch 793 the test accuracy over the whole test set is 37 %\n",
      "[794,     8] loss: 0.002\n",
      "For epoch 794 the test accuracy over the whole test set is 37 %\n",
      "[795,     8] loss: 0.002\n",
      "For epoch 795 the test accuracy over the whole test set is 37 %\n",
      "[796,     8] loss: 0.002\n",
      "For epoch 796 the test accuracy over the whole test set is 37 %\n",
      "[797,     8] loss: 0.002\n",
      "For epoch 797 the test accuracy over the whole test set is 37 %\n",
      "[798,     8] loss: 0.002\n",
      "For epoch 798 the test accuracy over the whole test set is 37 %\n",
      "[799,     8] loss: 0.002\n",
      "For epoch 799 the test accuracy over the whole test set is 37 %\n",
      "[800,     8] loss: 0.002\n",
      "For epoch 800 the test accuracy over the whole test set is 37 %\n",
      "[801,     8] loss: 0.002\n",
      "For epoch 801 the test accuracy over the whole test set is 37 %\n",
      "[802,     8] loss: 0.002\n",
      "For epoch 802 the test accuracy over the whole test set is 37 %\n",
      "[803,     8] loss: 0.002\n",
      "For epoch 803 the test accuracy over the whole test set is 37 %\n",
      "[804,     8] loss: 0.002\n",
      "For epoch 804 the test accuracy over the whole test set is 37 %\n",
      "[805,     8] loss: 0.002\n",
      "For epoch 805 the test accuracy over the whole test set is 37 %\n",
      "[806,     8] loss: 0.002\n",
      "For epoch 806 the test accuracy over the whole test set is 37 %\n",
      "[807,     8] loss: 0.002\n",
      "For epoch 807 the test accuracy over the whole test set is 37 %\n",
      "[808,     8] loss: 0.002\n",
      "For epoch 808 the test accuracy over the whole test set is 37 %\n",
      "[809,     8] loss: 0.002\n",
      "For epoch 809 the test accuracy over the whole test set is 37 %\n",
      "[810,     8] loss: 0.002\n",
      "For epoch 810 the test accuracy over the whole test set is 37 %\n",
      "[811,     8] loss: 0.002\n",
      "For epoch 811 the test accuracy over the whole test set is 37 %\n",
      "[812,     8] loss: 0.002\n",
      "For epoch 812 the test accuracy over the whole test set is 37 %\n",
      "[813,     8] loss: 0.002\n",
      "For epoch 813 the test accuracy over the whole test set is 37 %\n",
      "[814,     8] loss: 0.002\n",
      "For epoch 814 the test accuracy over the whole test set is 37 %\n",
      "[815,     8] loss: 0.002\n",
      "For epoch 815 the test accuracy over the whole test set is 37 %\n",
      "[816,     8] loss: 0.002\n",
      "For epoch 816 the test accuracy over the whole test set is 37 %\n",
      "[817,     8] loss: 0.002\n",
      "For epoch 817 the test accuracy over the whole test set is 37 %\n",
      "[818,     8] loss: 0.002\n",
      "For epoch 818 the test accuracy over the whole test set is 37 %\n",
      "[819,     8] loss: 0.002\n",
      "For epoch 819 the test accuracy over the whole test set is 37 %\n",
      "[820,     8] loss: 0.002\n",
      "For epoch 820 the test accuracy over the whole test set is 37 %\n",
      "[821,     8] loss: 0.002\n",
      "For epoch 821 the test accuracy over the whole test set is 37 %\n",
      "[822,     8] loss: 0.002\n",
      "For epoch 822 the test accuracy over the whole test set is 37 %\n",
      "[823,     8] loss: 0.002\n",
      "For epoch 823 the test accuracy over the whole test set is 37 %\n",
      "[824,     8] loss: 0.002\n",
      "For epoch 824 the test accuracy over the whole test set is 37 %\n",
      "[825,     8] loss: 0.002\n",
      "For epoch 825 the test accuracy over the whole test set is 37 %\n",
      "[826,     8] loss: 0.002\n",
      "For epoch 826 the test accuracy over the whole test set is 37 %\n",
      "[827,     8] loss: 0.002\n",
      "For epoch 827 the test accuracy over the whole test set is 37 %\n",
      "[828,     8] loss: 0.002\n",
      "For epoch 828 the test accuracy over the whole test set is 37 %\n",
      "[829,     8] loss: 0.002\n",
      "For epoch 829 the test accuracy over the whole test set is 37 %\n",
      "[830,     8] loss: 0.002\n",
      "For epoch 830 the test accuracy over the whole test set is 37 %\n",
      "[831,     8] loss: 0.002\n",
      "For epoch 831 the test accuracy over the whole test set is 37 %\n",
      "[832,     8] loss: 0.002\n",
      "For epoch 832 the test accuracy over the whole test set is 37 %\n",
      "[833,     8] loss: 0.002\n",
      "For epoch 833 the test accuracy over the whole test set is 37 %\n",
      "[834,     8] loss: 0.002\n",
      "For epoch 834 the test accuracy over the whole test set is 37 %\n",
      "[835,     8] loss: 0.002\n",
      "For epoch 835 the test accuracy over the whole test set is 37 %\n",
      "[836,     8] loss: 0.002\n",
      "For epoch 836 the test accuracy over the whole test set is 37 %\n",
      "[837,     8] loss: 0.002\n",
      "For epoch 837 the test accuracy over the whole test set is 37 %\n",
      "[838,     8] loss: 0.002\n",
      "For epoch 838 the test accuracy over the whole test set is 37 %\n",
      "[839,     8] loss: 0.002\n",
      "For epoch 839 the test accuracy over the whole test set is 37 %\n",
      "[840,     8] loss: 0.002\n",
      "For epoch 840 the test accuracy over the whole test set is 37 %\n",
      "[841,     8] loss: 0.002\n",
      "For epoch 841 the test accuracy over the whole test set is 37 %\n",
      "[842,     8] loss: 0.002\n",
      "For epoch 842 the test accuracy over the whole test set is 37 %\n",
      "[843,     8] loss: 0.002\n",
      "For epoch 843 the test accuracy over the whole test set is 37 %\n",
      "[844,     8] loss: 0.002\n",
      "For epoch 844 the test accuracy over the whole test set is 37 %\n",
      "[845,     8] loss: 0.002\n",
      "For epoch 845 the test accuracy over the whole test set is 37 %\n",
      "[846,     8] loss: 0.002\n",
      "For epoch 846 the test accuracy over the whole test set is 37 %\n",
      "[847,     8] loss: 0.002\n",
      "For epoch 847 the test accuracy over the whole test set is 37 %\n",
      "[848,     8] loss: 0.002\n",
      "For epoch 848 the test accuracy over the whole test set is 37 %\n",
      "[849,     8] loss: 0.002\n",
      "For epoch 849 the test accuracy over the whole test set is 37 %\n",
      "[850,     8] loss: 0.002\n",
      "For epoch 850 the test accuracy over the whole test set is 37 %\n",
      "[851,     8] loss: 0.002\n",
      "For epoch 851 the test accuracy over the whole test set is 37 %\n",
      "[852,     8] loss: 0.002\n",
      "For epoch 852 the test accuracy over the whole test set is 37 %\n",
      "[853,     8] loss: 0.002\n",
      "For epoch 853 the test accuracy over the whole test set is 37 %\n",
      "[854,     8] loss: 0.002\n",
      "For epoch 854 the test accuracy over the whole test set is 37 %\n",
      "[855,     8] loss: 0.002\n",
      "For epoch 855 the test accuracy over the whole test set is 37 %\n",
      "[856,     8] loss: 0.002\n",
      "For epoch 856 the test accuracy over the whole test set is 37 %\n",
      "[857,     8] loss: 0.002\n",
      "For epoch 857 the test accuracy over the whole test set is 37 %\n",
      "[858,     8] loss: 0.002\n",
      "For epoch 858 the test accuracy over the whole test set is 37 %\n",
      "[859,     8] loss: 0.002\n",
      "For epoch 859 the test accuracy over the whole test set is 37 %\n",
      "[860,     8] loss: 0.002\n",
      "For epoch 860 the test accuracy over the whole test set is 37 %\n",
      "[861,     8] loss: 0.002\n",
      "For epoch 861 the test accuracy over the whole test set is 37 %\n",
      "[862,     8] loss: 0.002\n",
      "For epoch 862 the test accuracy over the whole test set is 37 %\n",
      "[863,     8] loss: 0.002\n",
      "For epoch 863 the test accuracy over the whole test set is 37 %\n",
      "[864,     8] loss: 0.002\n",
      "For epoch 864 the test accuracy over the whole test set is 37 %\n",
      "[865,     8] loss: 0.002\n",
      "For epoch 865 the test accuracy over the whole test set is 37 %\n",
      "[866,     8] loss: 0.002\n",
      "For epoch 866 the test accuracy over the whole test set is 37 %\n",
      "[867,     8] loss: 0.002\n",
      "For epoch 867 the test accuracy over the whole test set is 37 %\n",
      "[868,     8] loss: 0.002\n",
      "For epoch 868 the test accuracy over the whole test set is 37 %\n",
      "[869,     8] loss: 0.002\n",
      "For epoch 869 the test accuracy over the whole test set is 37 %\n",
      "[870,     8] loss: 0.002\n",
      "For epoch 870 the test accuracy over the whole test set is 37 %\n",
      "[871,     8] loss: 0.002\n",
      "For epoch 871 the test accuracy over the whole test set is 37 %\n",
      "[872,     8] loss: 0.002\n",
      "For epoch 872 the test accuracy over the whole test set is 37 %\n",
      "[873,     8] loss: 0.002\n",
      "For epoch 873 the test accuracy over the whole test set is 37 %\n",
      "[874,     8] loss: 0.002\n",
      "For epoch 874 the test accuracy over the whole test set is 37 %\n",
      "[875,     8] loss: 0.002\n",
      "For epoch 875 the test accuracy over the whole test set is 37 %\n",
      "[876,     8] loss: 0.002\n",
      "For epoch 876 the test accuracy over the whole test set is 37 %\n",
      "[877,     8] loss: 0.002\n",
      "For epoch 877 the test accuracy over the whole test set is 37 %\n",
      "[878,     8] loss: 0.002\n",
      "For epoch 878 the test accuracy over the whole test set is 37 %\n",
      "[879,     8] loss: 0.002\n",
      "For epoch 879 the test accuracy over the whole test set is 37 %\n",
      "[880,     8] loss: 0.002\n",
      "For epoch 880 the test accuracy over the whole test set is 37 %\n",
      "[881,     8] loss: 0.002\n",
      "For epoch 881 the test accuracy over the whole test set is 37 %\n",
      "[882,     8] loss: 0.002\n",
      "For epoch 882 the test accuracy over the whole test set is 37 %\n",
      "[883,     8] loss: 0.002\n",
      "For epoch 883 the test accuracy over the whole test set is 37 %\n",
      "[884,     8] loss: 0.002\n",
      "For epoch 884 the test accuracy over the whole test set is 37 %\n",
      "[885,     8] loss: 0.002\n",
      "For epoch 885 the test accuracy over the whole test set is 37 %\n",
      "[886,     8] loss: 0.002\n",
      "For epoch 886 the test accuracy over the whole test set is 37 %\n",
      "[887,     8] loss: 0.002\n",
      "For epoch 887 the test accuracy over the whole test set is 37 %\n",
      "[888,     8] loss: 0.002\n",
      "For epoch 888 the test accuracy over the whole test set is 37 %\n",
      "[889,     8] loss: 0.002\n",
      "For epoch 889 the test accuracy over the whole test set is 37 %\n",
      "[890,     8] loss: 0.002\n",
      "For epoch 890 the test accuracy over the whole test set is 37 %\n",
      "[891,     8] loss: 0.002\n",
      "For epoch 891 the test accuracy over the whole test set is 37 %\n",
      "[892,     8] loss: 0.002\n",
      "For epoch 892 the test accuracy over the whole test set is 37 %\n",
      "[893,     8] loss: 0.002\n",
      "For epoch 893 the test accuracy over the whole test set is 37 %\n",
      "[894,     8] loss: 0.002\n",
      "For epoch 894 the test accuracy over the whole test set is 37 %\n",
      "[895,     8] loss: 0.002\n",
      "For epoch 895 the test accuracy over the whole test set is 37 %\n",
      "[896,     8] loss: 0.002\n",
      "For epoch 896 the test accuracy over the whole test set is 37 %\n",
      "[897,     8] loss: 0.002\n",
      "For epoch 897 the test accuracy over the whole test set is 37 %\n",
      "[898,     8] loss: 0.002\n",
      "For epoch 898 the test accuracy over the whole test set is 37 %\n",
      "[899,     8] loss: 0.002\n",
      "For epoch 899 the test accuracy over the whole test set is 37 %\n",
      "[900,     8] loss: 0.002\n",
      "For epoch 900 the test accuracy over the whole test set is 37 %\n",
      "[901,     8] loss: 0.002\n",
      "For epoch 901 the test accuracy over the whole test set is 37 %\n",
      "[902,     8] loss: 0.002\n",
      "For epoch 902 the test accuracy over the whole test set is 37 %\n",
      "[903,     8] loss: 0.002\n",
      "For epoch 903 the test accuracy over the whole test set is 37 %\n",
      "[904,     8] loss: 0.002\n",
      "For epoch 904 the test accuracy over the whole test set is 37 %\n",
      "[905,     8] loss: 0.002\n",
      "For epoch 905 the test accuracy over the whole test set is 37 %\n",
      "[906,     8] loss: 0.002\n",
      "For epoch 906 the test accuracy over the whole test set is 37 %\n",
      "[907,     8] loss: 0.002\n",
      "For epoch 907 the test accuracy over the whole test set is 37 %\n",
      "[908,     8] loss: 0.002\n",
      "For epoch 908 the test accuracy over the whole test set is 37 %\n",
      "[909,     8] loss: 0.002\n",
      "For epoch 909 the test accuracy over the whole test set is 37 %\n",
      "[910,     8] loss: 0.002\n",
      "For epoch 910 the test accuracy over the whole test set is 37 %\n",
      "[911,     8] loss: 0.002\n",
      "For epoch 911 the test accuracy over the whole test set is 37 %\n",
      "[912,     8] loss: 0.002\n",
      "For epoch 912 the test accuracy over the whole test set is 37 %\n",
      "[913,     8] loss: 0.002\n",
      "For epoch 913 the test accuracy over the whole test set is 37 %\n",
      "[914,     8] loss: 0.002\n",
      "For epoch 914 the test accuracy over the whole test set is 37 %\n",
      "[915,     8] loss: 0.002\n",
      "For epoch 915 the test accuracy over the whole test set is 37 %\n",
      "[916,     8] loss: 0.002\n",
      "For epoch 916 the test accuracy over the whole test set is 37 %\n",
      "[917,     8] loss: 0.002\n",
      "For epoch 917 the test accuracy over the whole test set is 37 %\n",
      "[918,     8] loss: 0.002\n",
      "For epoch 918 the test accuracy over the whole test set is 37 %\n",
      "[919,     8] loss: 0.002\n",
      "For epoch 919 the test accuracy over the whole test set is 37 %\n",
      "[920,     8] loss: 0.002\n",
      "For epoch 920 the test accuracy over the whole test set is 37 %\n",
      "[921,     8] loss: 0.002\n",
      "For epoch 921 the test accuracy over the whole test set is 37 %\n",
      "[922,     8] loss: 0.002\n",
      "For epoch 922 the test accuracy over the whole test set is 37 %\n",
      "[923,     8] loss: 0.002\n",
      "For epoch 923 the test accuracy over the whole test set is 37 %\n",
      "[924,     8] loss: 0.002\n",
      "For epoch 924 the test accuracy over the whole test set is 37 %\n",
      "[925,     8] loss: 0.002\n",
      "For epoch 925 the test accuracy over the whole test set is 37 %\n",
      "[926,     8] loss: 0.002\n",
      "For epoch 926 the test accuracy over the whole test set is 37 %\n",
      "[927,     8] loss: 0.002\n",
      "For epoch 927 the test accuracy over the whole test set is 37 %\n",
      "[928,     8] loss: 0.002\n",
      "For epoch 928 the test accuracy over the whole test set is 37 %\n",
      "[929,     8] loss: 0.002\n",
      "For epoch 929 the test accuracy over the whole test set is 37 %\n",
      "[930,     8] loss: 0.002\n",
      "For epoch 930 the test accuracy over the whole test set is 37 %\n",
      "[931,     8] loss: 0.002\n",
      "For epoch 931 the test accuracy over the whole test set is 37 %\n",
      "[932,     8] loss: 0.002\n",
      "For epoch 932 the test accuracy over the whole test set is 37 %\n",
      "[933,     8] loss: 0.002\n",
      "For epoch 933 the test accuracy over the whole test set is 37 %\n",
      "[934,     8] loss: 0.002\n",
      "For epoch 934 the test accuracy over the whole test set is 37 %\n",
      "[935,     8] loss: 0.002\n",
      "For epoch 935 the test accuracy over the whole test set is 37 %\n",
      "[936,     8] loss: 0.002\n",
      "For epoch 936 the test accuracy over the whole test set is 37 %\n",
      "[937,     8] loss: 0.002\n",
      "For epoch 937 the test accuracy over the whole test set is 37 %\n",
      "[938,     8] loss: 0.002\n",
      "For epoch 938 the test accuracy over the whole test set is 37 %\n",
      "[939,     8] loss: 0.002\n",
      "For epoch 939 the test accuracy over the whole test set is 37 %\n",
      "[940,     8] loss: 0.002\n",
      "For epoch 940 the test accuracy over the whole test set is 37 %\n",
      "[941,     8] loss: 0.002\n",
      "For epoch 941 the test accuracy over the whole test set is 37 %\n",
      "[942,     8] loss: 0.002\n",
      "For epoch 942 the test accuracy over the whole test set is 37 %\n",
      "[943,     8] loss: 0.002\n",
      "For epoch 943 the test accuracy over the whole test set is 37 %\n",
      "[944,     8] loss: 0.002\n",
      "For epoch 944 the test accuracy over the whole test set is 37 %\n",
      "[945,     8] loss: 0.002\n",
      "For epoch 945 the test accuracy over the whole test set is 37 %\n",
      "[946,     8] loss: 0.002\n",
      "For epoch 946 the test accuracy over the whole test set is 37 %\n",
      "[947,     8] loss: 0.002\n",
      "For epoch 947 the test accuracy over the whole test set is 37 %\n",
      "[948,     8] loss: 0.002\n",
      "For epoch 948 the test accuracy over the whole test set is 37 %\n",
      "[949,     8] loss: 0.002\n",
      "For epoch 949 the test accuracy over the whole test set is 37 %\n",
      "[950,     8] loss: 0.002\n",
      "For epoch 950 the test accuracy over the whole test set is 37 %\n",
      "[951,     8] loss: 0.002\n",
      "For epoch 951 the test accuracy over the whole test set is 37 %\n",
      "[952,     8] loss: 0.002\n",
      "For epoch 952 the test accuracy over the whole test set is 37 %\n",
      "[953,     8] loss: 0.002\n",
      "For epoch 953 the test accuracy over the whole test set is 37 %\n",
      "[954,     8] loss: 0.002\n",
      "For epoch 954 the test accuracy over the whole test set is 37 %\n",
      "[955,     8] loss: 0.002\n",
      "For epoch 955 the test accuracy over the whole test set is 37 %\n",
      "[956,     8] loss: 0.002\n",
      "For epoch 956 the test accuracy over the whole test set is 37 %\n",
      "[957,     8] loss: 0.002\n",
      "For epoch 957 the test accuracy over the whole test set is 37 %\n",
      "[958,     8] loss: 0.002\n",
      "For epoch 958 the test accuracy over the whole test set is 37 %\n",
      "[959,     8] loss: 0.002\n",
      "For epoch 959 the test accuracy over the whole test set is 37 %\n",
      "[960,     8] loss: 0.002\n",
      "For epoch 960 the test accuracy over the whole test set is 37 %\n",
      "[961,     8] loss: 0.002\n",
      "For epoch 961 the test accuracy over the whole test set is 37 %\n",
      "[962,     8] loss: 0.002\n",
      "For epoch 962 the test accuracy over the whole test set is 37 %\n",
      "[963,     8] loss: 0.002\n",
      "For epoch 963 the test accuracy over the whole test set is 37 %\n",
      "[964,     8] loss: 0.002\n",
      "For epoch 964 the test accuracy over the whole test set is 37 %\n",
      "[965,     8] loss: 0.002\n",
      "For epoch 965 the test accuracy over the whole test set is 37 %\n",
      "[966,     8] loss: 0.002\n",
      "For epoch 966 the test accuracy over the whole test set is 37 %\n",
      "[967,     8] loss: 0.002\n",
      "For epoch 967 the test accuracy over the whole test set is 37 %\n",
      "[968,     8] loss: 0.002\n",
      "For epoch 968 the test accuracy over the whole test set is 37 %\n",
      "[969,     8] loss: 0.002\n",
      "For epoch 969 the test accuracy over the whole test set is 37 %\n",
      "[970,     8] loss: 0.002\n",
      "For epoch 970 the test accuracy over the whole test set is 37 %\n",
      "[971,     8] loss: 0.002\n",
      "For epoch 971 the test accuracy over the whole test set is 37 %\n",
      "[972,     8] loss: 0.002\n",
      "For epoch 972 the test accuracy over the whole test set is 37 %\n",
      "[973,     8] loss: 0.002\n",
      "For epoch 973 the test accuracy over the whole test set is 37 %\n",
      "[974,     8] loss: 0.002\n",
      "For epoch 974 the test accuracy over the whole test set is 37 %\n",
      "[975,     8] loss: 0.002\n",
      "For epoch 975 the test accuracy over the whole test set is 37 %\n",
      "[976,     8] loss: 0.002\n",
      "For epoch 976 the test accuracy over the whole test set is 37 %\n",
      "[977,     8] loss: 0.002\n",
      "For epoch 977 the test accuracy over the whole test set is 37 %\n",
      "[978,     8] loss: 0.002\n",
      "For epoch 978 the test accuracy over the whole test set is 37 %\n",
      "[979,     8] loss: 0.002\n",
      "For epoch 979 the test accuracy over the whole test set is 37 %\n",
      "[980,     8] loss: 0.002\n",
      "For epoch 980 the test accuracy over the whole test set is 37 %\n",
      "[981,     8] loss: 0.002\n",
      "For epoch 981 the test accuracy over the whole test set is 37 %\n",
      "[982,     8] loss: 0.002\n",
      "For epoch 982 the test accuracy over the whole test set is 37 %\n",
      "[983,     8] loss: 0.002\n",
      "For epoch 983 the test accuracy over the whole test set is 37 %\n",
      "[984,     8] loss: 0.002\n",
      "For epoch 984 the test accuracy over the whole test set is 37 %\n",
      "[985,     8] loss: 0.002\n",
      "For epoch 985 the test accuracy over the whole test set is 37 %\n",
      "[986,     8] loss: 0.002\n",
      "For epoch 986 the test accuracy over the whole test set is 37 %\n",
      "[987,     8] loss: 0.002\n",
      "For epoch 987 the test accuracy over the whole test set is 37 %\n",
      "[988,     8] loss: 0.002\n",
      "For epoch 988 the test accuracy over the whole test set is 37 %\n",
      "[989,     8] loss: 0.002\n",
      "For epoch 989 the test accuracy over the whole test set is 37 %\n",
      "[990,     8] loss: 0.002\n",
      "For epoch 990 the test accuracy over the whole test set is 37 %\n",
      "[991,     8] loss: 0.002\n",
      "For epoch 991 the test accuracy over the whole test set is 37 %\n",
      "[992,     8] loss: 0.002\n",
      "For epoch 992 the test accuracy over the whole test set is 37 %\n",
      "[993,     8] loss: 0.002\n",
      "For epoch 993 the test accuracy over the whole test set is 37 %\n",
      "[994,     8] loss: 0.002\n",
      "For epoch 994 the test accuracy over the whole test set is 37 %\n",
      "[995,     8] loss: 0.002\n",
      "For epoch 995 the test accuracy over the whole test set is 37 %\n",
      "[996,     8] loss: 0.002\n",
      "For epoch 996 the test accuracy over the whole test set is 37 %\n",
      "[997,     8] loss: 0.002\n",
      "For epoch 997 the test accuracy over the whole test set is 37 %\n",
      "[998,     8] loss: 0.002\n",
      "For epoch 998 the test accuracy over the whole test set is 37 %\n",
      "[999,     8] loss: 0.002\n",
      "For epoch 999 the test accuracy over the whole test set is 37 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(num_of_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model re-load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a dummy input tuple  \n",
    "dummy_input = (1)\n",
    "\n",
    "# we can load the saved model and do the inference again \n",
    "load_model=LinearRegression(dummy_input)\n",
    "load_model.load_state_dict(torch.load('saved/Network.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Model has been converted to ONNX\n"
     ]
    }
   ],
   "source": [
    "export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
