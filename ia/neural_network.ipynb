{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.onnx \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaño de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and columns in one JSON file is (166, 6)\n"
     ]
    }
   ],
   "source": [
    "df_shape = df.shape\n",
    "print(f'Rows and columns in one JSON file is {df_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeros 10 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 columns in one JSON file is                    name artist  year gender   likes  bought\n",
      "0                 Queen  Queen  1973   Rock  3258.0    True\n",
      "1              Queen II  Queen  1974   Rock  4017.0    True\n",
      "2    Sheer Heart Attack  Queen  1974   Rock  2427.0   False\n",
      "3  A Night at the Opera  Queen  1975   Rock  2712.0   False\n",
      "4     News of the World  Queen  1977   Rock  3488.0    True\n",
      "5                  Jazz  Queen  1978   Rock  1377.0   False\n",
      "6              The Game  Queen  1980   Rock  6636.0    True\n",
      "7             Hot Space  Queen  1982   Rock  1762.0   False\n",
      "8             The Works  Queen  1984   Rock  5530.0   False\n",
      "9       A Kind of Magic  Queen  1986   Rock  3328.0    True\n"
     ]
    }
   ],
   "source": [
    "df_rows = df.head(10)\n",
    "print(f'First 10 columns in one JSON file is {df_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are :\n",
      "#########\n",
      "name\n",
      "artist\n",
      "year\n",
      "gender\n",
      "likes\n",
      "bought\n"
     ]
    }
   ],
   "source": [
    "print(f'The column names are :')\n",
    "print('#########')\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas de Dataset en base a filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = df.filter(regex='nam').columns\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Información general de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The #rows and #columns are  166  and  6\n",
      "The years in this dataset are:  [1973 1974 1975 1977 1978 1980 1982 1984 1986 1989 1991 1995 1993 1963\n",
      " 1964 1965 1966 1967 1968 1970 1976 1979 1981 2021 2012 2015 2017 2018\n",
      " 1999 2001 2003 2006 2009 2022 1969 1971 1972 1983 1987 1997 2002 2013\n",
      " 2016 1996 2000 2010 2014 2004 2005 2008 2019 2020 2024 1956 1957 1960\n",
      " 1961 1962 1985]\n",
      "The artists covered in this dataset are:  ['Queen', 'Nirvana', 'The Beatles', 'ABBA', 'Imagine Dragons', 'MUSE', 'Rosalía', 'David Bowie', 'Spice Girls', 'Michael Jackson', 'Archive', 'Daft Punk', 'Taylor Swift', 'Elvis Presley', 'Supertramp']\n",
      "The genders covered are:  ['Rock', 'Pop', 'Pop Rock', 'Alternative Rock', 'Flamenco', 'Electronic', 'Rock and Roll', 'Progressive Pop']\n"
     ]
    }
   ],
   "source": [
    "print(\"The #rows and #columns are \", df.shape[0] , \" and \", df.shape[1])\n",
    "print(\"The years in this dataset are: \", df.year.unique())\n",
    "print(\"The artists covered in this dataset are: \", list(df.artist.unique()))\n",
    "print(\"The genders covered are: \", list(df.gender.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registros  de Dataset en base a filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock and Roll</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronic</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Progressive Pop</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative Rock</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop Rock</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flamenco</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count\n",
       "gender                 \n",
       "Rock                 64\n",
       "Pop                  36\n",
       "Rock and Roll        23\n",
       "Electronic           16\n",
       "Progressive Pop      11\n",
       "Alternative Rock      9\n",
       "Pop Rock              4\n",
       "Flamenco              3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.DataFrame({'Count':df.gender.value_counts()})\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta de Registros de Dataset en base a filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alternative Rock</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronic</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flamenco</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop Rock</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Progressive Pop</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock and Roll</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count\n",
       "gender                 \n",
       "Alternative Rock      9\n",
       "Electronic           16\n",
       "Flamenco              3\n",
       "Pop                  36\n",
       "Pop Rock              4\n",
       "Progressive Pop      11\n",
       "Rock                 64\n",
       "Rock and Roll        23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.sort_values(by=['gender'],ascending=True).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombrado de Columna de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bought':'is_bought'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizado de registros con valores Nulor de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         0\n",
       "artist       0\n",
       "year         0\n",
       "gender       0\n",
       "likes        4\n",
       "is_bought    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df.likes.isnull()]\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='is_bought', ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'is_bought', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de Columnas Categorícas de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are :\n",
      "#########\n",
      "is_bought\n",
      "likes\n",
      "name\n",
      "artist\n",
      "year\n",
      "gender\n",
      "The column types are :\n",
      "#########\n",
      "bool\n",
      "float64\n",
      "category\n",
      "category\n",
      "category\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "data_orig = df.copy()\n",
    "data = df[['is_bought', 'likes','name', 'artist', 'year', 'gender']]\n",
    "categorical_columns  = ['name', 'artist', 'year','gender']\n",
    "for c in categorical_columns:\n",
    "    data[c] = data[c].astype('category')\n",
    "    \n",
    "print(f'The column names are :')\n",
    "print('#########')\n",
    "for col in data.columns:\n",
    "    print(col)\n",
    "\n",
    "print(f'The column types are :')\n",
    "print('#########')\n",
    "for col in data.dtypes:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminación de columnas categorícas de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j.pardo\\AppData\\Local\\Temp\\ipykernel_10528\\16605558.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_dummies = data_dummies.replace({True: 1, False: 0})\n"
     ]
    }
   ],
   "source": [
    "data_dummies = pd.get_dummies(data[categorical_columns], drop_first=True)\n",
    "data_dummies = data_dummies.replace({True: 1, False: 0})\n",
    "not_categorical_columns  = ['is_bought','likes']\n",
    "data = pd.concat([data, data_dummies], axis = 1)\n",
    "data.drop(categorical_columns,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Información general de Dataset Normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The #rows and #columns are  162  and  238\n"
     ]
    }
   ],
   "source": [
    "print(\"The #rows and #columns are \", data.shape[0] , \" and \", data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas de Dataset Normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names are :\n",
      "#########\n",
      "is_bought\n",
      "likes\n",
      "name_...Famous Last Words... \n",
      "name_1989\n",
      "name_A Hard Day's Night\n",
      "name_A Kind of Magic\n",
      "name_A Night at the Opera\n",
      "name_ABBA\n",
      "name_Abbey Road\n",
      "name_Absolution\n",
      "name_Aladdin Sane\n",
      "name_Arrival\n",
      "name_Axiom\n",
      "name_Bad\n",
      "name_Beatles '65\n",
      "name_Beatles VI\n",
      "name_Beatles for Sale\n",
      "name_Ben\n",
      "name_Black Holes and Revelations\n",
      "name_Black Tie White Noise\n",
      "name_Bleach\n",
      "name_Blood on the Dance Floor: History in the Mix\n",
      "name_Breakfast in America\n",
      "name_Brother Where You Bound\n",
      "name_Call to Arms and Angels\n",
      "name_Controlling Crowds\n",
      "name_Controlling Crowds – Part IV\n",
      "name_Crime of the Century \n",
      "name_Crisis? What Crisis?\n",
      "name_Dangerous\n",
      "name_Diamond Dogs\n",
      "name_Discovery\n",
      "name_Drones\n",
      "name_Earthlinge\n",
      "name_El mal querer\n",
      "name_Elvis\n",
      "name_Elvis Is Back!\n",
      "name_Elvis Now\n",
      "name_Elvis Presley\n",
      "name_Elvis for Everyone!\n",
      "name_Elvis sings The Wonderful World of Christmas\n",
      "name_Elvis' Christmas Album\n",
      "name_Even in the Quietest Moments...\n",
      "name_Evermore\n",
      "name_Fearless\n",
      "name_Folklore\n",
      "name_Forever\n",
      "name_Forever, Michael\n",
      "name_Free as a Bird\n",
      "name_From Elvis Presley Boulevard, Memphis, Tennessee\n",
      "name_From Elvis in Memphis\n",
      "name_From Memphis to Vegas / From Vegas to Memphis \n",
      "name_Got to Be There\n",
      "name_He Touched Me \n",
      "name_Heathen\n",
      "name_Help!\n",
      "name_His Hand in Mine\n",
      "name_History: Past, Present and Future, Book I\n",
      "name_Homework\n",
      "name_Hot Space\n",
      "name_Hours...\n",
      "name_How Great Thou Art \n",
      "name_Human After All\n",
      "name_Hunky Dory\n",
      "name_In Utero\n",
      "name_Indelibly Stamped\n",
      "name_Innuendo\n",
      "name_Introducing... The Beatles\n",
      "name_Invincible\n",
      "name_Jazz\n",
      "name_Let It Be\n",
      "name_Let's Dance\n",
      "name_Lights \n",
      "name_Lodger\n",
      "name_Londinium\n",
      "name_Los ángeles\n",
      "name_Love Letters from Elvis\n",
      "name_Lover\n",
      "name_Low\n",
      "name_Made in Heaven\n",
      "name_Magical Mystery Tour\n",
      "name_Meet the Beatles!\n",
      "name_Mercury – Act 1\n",
      "name_Michael\n",
      "name_Midnights\n",
      "name_Moody Blue\n",
      "name_Motomami\n",
      "name_Music and Me\n",
      "name_Never Let Me Down\n",
      "name_Nevermind\n",
      "name_News of the World\n",
      "name_Night Visions\n",
      "name_Noise\n",
      "name_Off the Wall\n",
      "name_Origin of Symmetry\n",
      "name_Origins\n",
      "name_Outside\n",
      "name_Pin Ups\n",
      "name_Please Please Me\n",
      "name_Pot Luck\n",
      "name_Promised Land \n",
      "name_Queen\n",
      "name_Queen II\n",
      "name_Random Access Memories\n",
      "name_Reality\n",
      "name_Red\n",
      "name_Reputation\n",
      "name_Restriction\n",
      "name_Revolver \n",
      "name_Ring Ring\n",
      "name_Rubber Soul\n",
      "name_Scary Monsters (and Super Creeps)\n",
      "name_Sgt. Pepper's Lonely Hearts Club Band\n",
      "name_Sheer Heart Attack\n",
      "name_Showbiz\n",
      "name_Simulation Theory\n",
      "name_Slow Motion\n",
      "name_Smoke + Mirrors\n",
      "name_Some Things Never Change\n",
      "name_Something New\n",
      "name_Something for Everybody\n",
      "name_Space Oddity\n",
      "name_Speak Now\n",
      "name_Spice\n",
      "name_Spiceworld\n",
      "name_Station to Station\n",
      "name_Super Trouper\n",
      "name_Supertramp\n",
      "name_Take My Head\n",
      "name_Taylor Swift\n",
      "name_That's the Way It Is\n",
      "name_The 2nd Law\n",
      "name_The Album\n",
      "name_The BEATLES\n",
      "name_The Beatles' Second Album\n",
      "name_The Early Beatles\n",
      "name_The False Foundation\n",
      "name_The Game\n",
      "name_The Man Who Sold the World\n",
      "name_The Miracle\n",
      "name_The Next Day\n",
      "name_The Resistance\n",
      "name_The Rise and Fall of Ziggy Stardust and the Spiders from Mars\n",
      "name_The Visitors\n",
      "name_The Works\n",
      "name_Thriller\n",
      "name_Today\n",
      "name_Tonight\n",
      "name_Voulez-Vous\n",
      "name_Voyage\n",
      "name_Waterloo\n",
      "name_Will of the People\n",
      "name_With Us Until You're Dead \n",
      "name_With the Beatles\n",
      "name_Xscape\n",
      "name_Yellow Submarine\n",
      "name_Yesterday and Today\n",
      "name_You All Look the Same to Me  \n",
      "name_Young Americans\n",
      "name_★\n",
      "artist_Archive\n",
      "artist_Daft Punk\n",
      "artist_David Bowie\n",
      "artist_Elvis Presley\n",
      "artist_Imagine Dragons\n",
      "artist_MUSE\n",
      "artist_Michael Jackson\n",
      "artist_Nirvana\n",
      "artist_Queen\n",
      "artist_Rosalía\n",
      "artist_Spice Girls\n",
      "artist_Supertramp\n",
      "artist_Taylor Swift\n",
      "artist_The Beatles\n",
      "year_1957\n",
      "year_1960\n",
      "year_1961\n",
      "year_1962\n",
      "year_1963\n",
      "year_1964\n",
      "year_1965\n",
      "year_1966\n",
      "year_1967\n",
      "year_1968\n",
      "year_1969\n",
      "year_1970\n",
      "year_1971\n",
      "year_1972\n",
      "year_1973\n",
      "year_1974\n",
      "year_1975\n",
      "year_1976\n",
      "year_1977\n",
      "year_1978\n",
      "year_1979\n",
      "year_1980\n",
      "year_1981\n",
      "year_1982\n",
      "year_1983\n",
      "year_1984\n",
      "year_1985\n",
      "year_1986\n",
      "year_1987\n",
      "year_1989\n",
      "year_1991\n",
      "year_1993\n",
      "year_1995\n",
      "year_1996\n",
      "year_1997\n",
      "year_1999\n",
      "year_2000\n",
      "year_2001\n",
      "year_2002\n",
      "year_2003\n",
      "year_2004\n",
      "year_2005\n",
      "year_2006\n",
      "year_2008\n",
      "year_2009\n",
      "year_2010\n",
      "year_2012\n",
      "year_2013\n",
      "year_2014\n",
      "year_2015\n",
      "year_2016\n",
      "year_2017\n",
      "year_2018\n",
      "year_2019\n",
      "year_2020\n",
      "year_2021\n",
      "year_2022\n",
      "gender_Electronic\n",
      "gender_Flamenco\n",
      "gender_Pop\n",
      "gender_Pop Rock\n",
      "gender_Progressive Pop\n",
      "gender_Rock\n",
      "gender_Rock and Roll\n"
     ]
    }
   ],
   "source": [
    "print(f'The column names are :')\n",
    "print('#########')\n",
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombrado de Columna de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'is_bought':'target'}, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['likes']\n",
    "\n",
    "X = data[features]\n",
    "Y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuración de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_of_epochs = 1000\n",
    "learning_rate=0.01\n",
    "weight_decay=0.0001\n",
    "test_size = 0.33\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación Dataset Entrenamiento / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logger TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self)-> None:\n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def __flush__(self) -> None:\n",
    "        self.writer.flush\n",
    "\n",
    "    def __del__(self) -> None:\n",
    "        self.writer.flush()\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self, X: np.ndarray, y: np.ndarray) -> None:  \n",
    "    self.X = torch.from_numpy(X.astype(np.float32))\n",
    "    self.y = torch.from_numpy(y.astype(np.float32))\n",
    "    self.len = self.X.shape[0]\n",
    "\n",
    "  def __getitem__(self, index: int) -> tuple:\n",
    "    return self.X[index], self.y[index]\n",
    "  \n",
    "  def __len__(self) -> int:\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargador de Lotes Entrenamiento / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(self, train:Data, test:Data) -> None:\n",
    "        self.train = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        self.test = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciado de Cargador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Data(X_train.values, y_train.values)\n",
    "testdata = Data(X_test.values, y_test.values)\n",
    "\n",
    "# create Loader to read the data within batch sizes and put into memory. \n",
    "loader = Loader(traindata, testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitectura de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module): # all the dependencies from torch will be given to this class [parent class] # nn.Module contains all the building block of neural networks:\n",
    "  def __init__(self,input_dim):\n",
    "    super(LinearRegression,self).__init__()   # building connection with parent and child classes\n",
    "    self.fc1=nn.Linear(input_dim,10)          # hidden layer 1\n",
    "    self.fc2=nn.Linear(10,5)                  # hidden layer 2\n",
    "    self.fc3=nn.Linear(5,3)                   # hidden layer 3\n",
    "    self.fc4=nn.Linear(3,1)                   # last layer\n",
    "\n",
    "  def forward(self,d):\n",
    "    out=torch.relu(self.fc1(d))              # input * weights + bias for layer 1\n",
    "    out=torch.relu(self.fc2(out))            # input * weights + bias for layer 2\n",
    "    out=torch.relu(self.fc3(out))            # input * weights + bias for layer 3\n",
    "    out=self.fc4(out)                        # input * weights + bias for last layer\n",
    "    return out                               # final outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializado de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "torch.manual_seed(42)  # to make initilized weights stable:\n",
    "model = LinearRegression(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de Pérdida, Factor de Aprendizaje & Optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function with Mean Squared Error loss and an optimizer with Adam optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizers=optim.Adam(params=model.parameters(),lr=learning_rate, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializado de Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Carga de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload()-> None:\n",
    "    # let's create a dummy input tuple  \n",
    "    dummy_input = (1)\n",
    "\n",
    "    # we can load the saved model and do the inference again \n",
    "    load_model=LinearRegression(dummy_input)\n",
    "    load_model.load_state_dict(torch.load('saved/Network.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardado de Parámetros de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model \n",
    "def save() -> None:\n",
    "    filename=Path('saved')\n",
    "    filename.mkdir(parents=True,exist_ok=True)    \n",
    "    model_name='Network.pth' \n",
    "\n",
    "    saving_path=filename/model_name   \n",
    "    torch.save(obj=model.state_dict(),f=saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportado de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Convert to ONNX \n",
    "def export(): \n",
    "\n",
    "    # set the model to inference mode \n",
    "    model.eval() \n",
    "\n",
    "    # let's create a dummy input tensor  \n",
    "    dummy_input = torch.randn(1)  \n",
    "\n",
    "    # export the model   \n",
    "    torch.onnx.export(model,         # model being run \n",
    "         dummy_input,       # model input (or a tuple for multiple inputs) \n",
    "         \"saved/Network.onnx\",       # where to save the model  \n",
    "         export_params=True,  # store the trained parameter weights inside the model file \n",
    "         opset_version=11,    # the ONNX version to export the model to \n",
    "         do_constant_folding=True,  # whether to execute constant folding for optimization \n",
    "         input_names = ['input'],   # the model's input names \n",
    "         output_names = ['output'], # the model's output names \n",
    "         dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes \n",
    "                                'output' : {0 : 'batch_size'}}) \n",
    "    print(\" \") \n",
    "    print('Model has been converted to ONNX') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspección de Arquitectura de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Inspect the model on TensorBoard \n",
    "def inspect() -> None:\n",
    "    \n",
    "    # let's create a dummy input tensor  \n",
    "    dummy_input = torch.randn(1)  \n",
    "\n",
    "    # we can inspect the model using TensorBoard\n",
    "    logger.writer.add_graph(model, dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test records\n",
    "def test(num_of_epochs: float = 1000) -> None:\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0  \n",
    "    best_accuracy = 0.0\n",
    " \n",
    "    # define your execution device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    logger.writer.add_text('config/model', model.__class__.__name__)\n",
    "    logger.writer.add_text('config/optimizer', optimizers.__class__.__name__)\n",
    "    logger.writer.add_text('config/device', str(device)) \n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "     # loop over the dataset multiple times\n",
    "    for epoch in range(num_of_epochs):\n",
    "\n",
    "        batch_loss = 0.0   \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for b, data in enumerate(loader.test, 0):        \n",
    "            \n",
    "                # get the inputs\n",
    "                inputs, targets = data            \n",
    "\n",
    "                # run the model on the test set to predict labels                \n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss_value = loss(outputs, targets)\n",
    "\n",
    "                # let's print statistics for every batch\n",
    "                batch_loss += loss_value.item()     \n",
    "\n",
    "                if b == data.__len__():         \n",
    "\n",
    "                    # log the batch loss\n",
    "                    logger.writer.add_scalar('test/batch/loss',batch_loss / data.__len__(),epoch * len(loader.train) + b)             \n",
    "\n",
    "                    # zero the loss\n",
    "                    batch_loss = 0.0      \n",
    "\n",
    "                global_step = epoch * len(loader.test) + b\n",
    "                \n",
    "                logger.writer.add_scalar('test/loss', loss_value.item(), global_step=global_step)\n",
    "                logger.writer.add_scalar('test/confidence', torch.mean(torch.max(torch.softmax(outputs, dim=1), dim=1)[0]).item(), global_step=global_step)\n",
    "\n",
    "                logger.writer.add_histogram('test/outputs', torch.max(outputs, dim=1)[0], global_step=global_step)\n",
    "                logger.writer.add_histogram('test/confidences', torch.max(torch.softmax(outputs, dim=1), dim=1)[0], global_step=global_step)\n",
    "                \n",
    "                \n",
    "                # the label with the highest energy will be our prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += targets.size(0)\n",
    "                accuracy += (predicted == targets).sum().item()\n",
    "        \n",
    "    # compute the accuracy over all test records\n",
    "    accuracy = (100 * accuracy / total)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "      save()     \n",
    "      best_accuracy = accuracy \n",
    "      \n",
    "    logger.__flush__()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "\n",
    "# The training routine is held simple, setting up inputs and targets,\n",
    "# zeroing the optimizer's gradients and finally doing a forward and backward\n",
    "# to update the parameters.\n",
    "def train(num_of_epochs: float = 1000) -> None:\n",
    " \n",
    "  # define your execution device\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  logger.writer.add_text('config/model', model.__class__.__name__)\n",
    "  logger.writer.add_text('config/optimizer', optimizers.__class__.__name__)\n",
    "  logger.writer.add_text('config/device', str(device)) \n",
    " \n",
    "  model.to(device)\n",
    "\n",
    "  # loop over the dataset multiple times\n",
    "  for epoch in range(num_of_epochs):\n",
    "\n",
    "    batch_loss = 0.0     \n",
    "   \n",
    "    for b, data in enumerate(loader.train, 0):  \n",
    "\n",
    "      # get the inputs\n",
    "      inputs, targets = data      \n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizers.zero_grad()\n",
    "\n",
    "      # predict classes using records from the training set\n",
    "      outputs=model(inputs) \n",
    "\n",
    "      # compute the loss based on model output and real targets\n",
    "      loss_value=loss(outputs, targets)    \n",
    "     \n",
    "      # backpropagate the loss\n",
    "      loss_value.backward()  \n",
    "\n",
    "      # adjust parameters based on the calculated gradients\n",
    "      optimizers.step() \n",
    "\n",
    "      global_step = epoch * len(loader.train) + b\n",
    "      logger.writer.add_scalar('train/loss', loss_value.item(), global_step=global_step)\n",
    "      logger.writer.add_scalar('train/confidence', torch.mean(torch.max(torch.softmax(outputs, dim=1), dim=1)[0]).item(), global_step=global_step)\n",
    "\n",
    "      logger.writer.add_histogram('train/outputs', torch.max(outputs, dim=1)[0], global_step=global_step)\n",
    "      logger.writer.add_histogram('train/confidences', torch.max(torch.softmax(outputs, dim=1), dim=1)[0], global_step=global_step)\n",
    "\n",
    "      # let's print statistics for every batch\n",
    "      batch_loss += loss_value.item()     \n",
    "     \n",
    "      if b == data.__len__():         \n",
    "\n",
    "        # log the batch loss\n",
    "        logger.writer.add_scalar('train/batch/loss',batch_loss / data.__len__(),epoch * len(loader.train) + b)             \n",
    "\n",
    "        # zero the loss\n",
    "        batch_loss = 0.0   \n",
    "\n",
    "  logger.__flush__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j.pardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\j.pardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j.pardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Model has been converted to ONNX\n"
     ]
    }
   ],
   "source": [
    "export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del logger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
